{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15448,
     "status": "ok",
     "timestamp": 1694581223575,
     "user": {
      "displayName": "Edwin Goh Duo Yao",
      "userId": "00967731948897399037"
     },
     "user_tz": -480
    },
    "id": "sGVaYwgXVbhe",
    "outputId": "9f0456f9-55d7-4fad-9136-646c45a5b1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.10/dist-packages (4.9.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.4.0)\n",
      "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.4.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.23.5)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (5.9.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.14.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.3.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (4.66.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (6.0.1)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (4.5.0)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2023.7.22)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.60.0)\n",
      "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (0.14.0)\n",
      "Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.57.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.33.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets\n",
    "!pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_7VxZ3gWBeW"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import tensorflow_datasets as tfds\n",
    "# Suppress warnings\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgxSSLlEmbQs"
   },
   "source": [
    "# **Loading The Portuguse To English Translation Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUwHnW3aXkTd"
   },
   "outputs": [],
   "source": [
    "translation_examples, translation_metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info = True, as_supervised = True)\n",
    "translation_training_examples, translation_validation_examples = translation_examples['train'], translation_examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1694581230612,
     "user": {
      "displayName": "Edwin Goh Duo Yao",
      "userId": "00967731948897399037"
     },
     "user_tz": -480
    },
    "id": "zxqGrnnOYlQC",
    "outputId": "6bda969c-99a7-4169-97e1-a1c3418fc75a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./Data/ted_hrlr_translate_pt_en_converter.zip'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.get_file('ted_hrlr_translate_pt_en_converter.zip',\n",
    "                        'https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip', cache_dir = '.',\n",
    "                        cache_subdir = '../Data', extract = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHnJ7SdGmrjV"
   },
   "source": [
    "# **Exploring The Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1694581231353,
     "user": {
      "displayName": "Edwin Goh Duo Yao",
      "userId": "00967731948897399037"
     },
     "user_tz": -480
    },
    "id": "SkXjTX5GeWph",
    "outputId": "c4c87d57-1c62-40b8-ffc2-e58aaff3666c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Examples in Portuguese\n",
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
      "mas e se estes fatores fossem ativos ?\n",
      "mas eles não tinham a curiosidade de me testar .\n",
      "> Examples in English\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "translation_tokenizers = tf.saved_model.load('../Data/ted_hrlr_translate_pt_en_converter')\n",
    "for portuguese_examples, english_examples in translation_training_examples.batch(3).take(1):\n",
    "  print('> Examples in Portuguese')\n",
    "  for pt in portuguese_examples.numpy():\n",
    "    print(pt.decode('utf-8'))\n",
    "  print('> Examples in English')\n",
    "  for en in english_examples.numpy():\n",
    "    print(en.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1694581232101,
     "user": {
      "displayName": "Edwin Goh Duo Yao",
      "userId": "00967731948897399037"
     },
     "user_tz": -480
    },
    "id": "iUPKqg5nfJrH",
    "outputId": "cf3d48cb-5181-4da2-cf59-db73ff134e60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]\n",
      "[2, 87, 90, 107, 76, 129, 1852, 30, 3]\n",
      "[2, 87, 83, 149, 50, 9, 56, 664, 85, 2512, 15, 3]\n"
     ]
    }
   ],
   "source": [
    "english_tokenizer_encoded = translation_tokenizers.en.tokenize(english_examples)\n",
    "for row in english_tokenizer_encoded.to_list():\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1694581232101,
     "user": {
      "displayName": "Edwin Goh Duo Yao",
      "userId": "00967731948897399037"
     },
     "user_tz": -480
    },
    "id": "28vWllqvgTOs",
    "outputId": "1ae3d040-7378-4979-975c-6c701dbe2347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n ' t test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "english_tokenizer_decoded = translation_tokenizers.en.detokenize(english_tokenizer_encoded)\n",
    "for line in english_tokenizer_decoded.numpy():\n",
    "  print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrnQXEWJmTJX"
   },
   "source": [
    "# **Creating The Input Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fm-LKemphg4S"
   },
   "outputs": [],
   "source": [
    "def filter_max_tokens(pt_example, en_example):\n",
    "  num_tokens = tf.maximum(tf.shape(pt_example)[1], tf.shape(en_example)[1])\n",
    "  return num_tokens < 128\n",
    "\n",
    "def tokenize_pairs(pt_example, en_example):\n",
    "  pt_example = translation_tokenizers.pt.tokenize(pt_example)\n",
    "  # Convert to dense tensor, padded with zeros\n",
    "  pt_example = pt_example.to_tensor()\n",
    "\n",
    "  en_example = translation_tokenizers.en.tokenize(en_example)\n",
    "  # Convert to dense tensor, padded with zeros\n",
    "  en_example = en_example.to_tensor()\n",
    "  return pt_example, en_example\n",
    "\n",
    "def make_batches(ds):\n",
    "  return ds.cache().shuffle(20000).batch(64).map(tokenize_pairs, num_parallel_calls = tf.data.AUTOTUNE).filter(filter_max_tokens).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "translation_training_batches = make_batches(translation_training_examples)\n",
    "translation_validation_batches = make_batches(translation_validation_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BVTS6dZmxQ0"
   },
   "source": [
    "# Adding The Positional Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlqBAyxMm9m8"
   },
   "outputs": [],
   "source": [
    "def get_angles(position, i, d_dimensional_model):\n",
    "  angle_rates = 1/np.power(10000, (2*(i//2))/np.float32(d_dimensional_model))\n",
    "  return position * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_dimensional_model):\n",
    "  angle_radians = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_dimensional_model)[np.newaxis, :], d_dimensional_model)\n",
    "  # For every even element in the array (2i)\n",
    "  angle_radians[:, 0::2] = np.sin(angle_radians[:, 0::2])\n",
    "  # For every odd element in the array (2i+1)\n",
    "  angle_radians[:, 1::2] = np.cos(angle_radians[:, 1::2])\n",
    "  return tf.cast(angle_radians[np.newaxis, ...], dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7Ry3lY8p4NE"
   },
   "source": [
    "# **Look-Ahead Mask - Masking Future Tokens In A Sequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVN2CJQVqB0e"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(sequence):\n",
    "  '''\n",
    "  Adding extra dimensions for the additional padding in the attention logits\n",
    "  '''\n",
    "  sequence = tf.cast(tf.math.equal(sequence, 0), tf.float32)\n",
    "  return sequence[:, tf.newaxis, tf.newaxis, :] # (batch_size, 1, 1, sequence_len)\n",
    "\n",
    "def create_lookahead_mask(size):\n",
    "  return 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0) # (sequence_len, sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hB8CYH8uSc4"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask = None):\n",
    "  '''\n",
    "  Calculates the attention weights. Returns both output and attention weights\n",
    "  Args\n",
    "    q : query shape == (..., sequence_len_q, depth_q)\n",
    "    k : key shape == (..., sequence_len_k, depth_k)\n",
    "    v : value shape == (..., sequence_len_v, depth_v)\n",
    "    mask : Float tensor with shape that is broadcastable to (..., sequence_len_q, sequence_len_k). Default = None\n",
    "  q, k, v : Must have matching leading dimensions\n",
    "  k, v : Must have matching penultimate dimension (sequence_len_k == sequence_len_v)\n",
    "  mask : Has different shapes depending on its type (padding/look-ahead) but it must be broadcastable for addition\n",
    "  '''\n",
    "  qk_matmul = tf.matmul(q, k, transpose_b = True) # output_shape = (..., sequence_len_q, sequence_len_k)\n",
    "  scaled_attention_logits = qk_matmul/tf.math.sqrt(tf.cast(tf.shape(k)[-1], tf.float32))\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "  # Normalize the last axis (sequence_len_k) using softmax to ensure that the scores add up to 1\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1) # output_shape = (..., sequence_len_q, sequence_len_k)\n",
    "  output = tf.matmul(attention_weights, v) # output_shape = (..., sequence_len_q, depth_v)\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDY034UlTFy6"
   },
   "source": [
    "# **Implementing The Multi-Head Attention Mechanism**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CT3B34NGNx9b"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, d_dimensional_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_dimensional_model = d_dimensional_model\n",
    "\n",
    "    assert d_dimensional_model % self.num_heads == 0\n",
    "    self.depth = d_dimensional_model//self.num_heads\n",
    "    self.wq = tf.keras.layers.Dense(d_dimensional_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_dimensional_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_dimensional_model)\n",
    "    self.dense = tf.keras.layers.Dense(d_dimensional_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    '''\n",
    "    Split the last dimension into (num_heads, depth) and transpose the result such that the shape = (batch_size, num_heads, sequence_len, depth)\n",
    "    '''\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm = [0, 2, 1, 3])\n",
    "\n",
    "  def call(self, v, k, q , mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q) # Shape: (batch_size, sequence_len, d_dimensional_model)\n",
    "    q = self.split_heads(q, batch_size) # Shape: (batch_size, num_heads, sequence_len_q, depth)\n",
    "    k = self.wk(k) # Shape: (batch_size, sequence_len, d_dimensional_model)\n",
    "    k = self.split_heads(k, batch_size) # Shape: (batch_size, num_heads, sequence_len_k, depth)\n",
    "    v = self.wv(v) # Shape: (batch_size, sequence_len, d_dimensional_model)\n",
    "    v = self.split_heads(v, batch_size) # Shape: (batch_size, num_heads, sequence_len_v, depth)\n",
    "\n",
    "    '''\n",
    "    scaled_attention.shape == (batch_size, num_heads, sequence_len_q, depth)\n",
    "    attention_weights.shape == (batch_size, num_heads, sequence_len_q, sequence_len_k)\n",
    "    '''\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm = [0, 2, 1, 3]) # Reshaped to (batch_size, sequence_len_q, num_heads, depth)\n",
    "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_dimensional_model)) # Shape: (batch_size, sequence_len_q, d_dimensional_model)\n",
    "    output = self.dense(concat_attention) # Shape: (batch_size, sequence_len_q, d_dimensional_model)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIove5cDTQYg"
   },
   "source": [
    "# **Defining The Point-Wise Feed-Forward Network (2 Fully-Connected Layers)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byaDrqePTgQL"
   },
   "outputs": [],
   "source": [
    "def pointwise_feed_forward_network(d_dimensional_model, dff):\n",
    "  return tf.keras.Sequential([tf.keras.layers.Dense(dff, activation = 'relu'), tf.keras.layers.Dense(d_dimensional_model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4ShrRBGUPW9"
   },
   "source": [
    "# **Defining The Encoder And Decoder Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "att84KsSUXwv"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, d_dimensional_model, num_heads, dff, dropout_rate = 0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "    self.MHA = MultiHeadAttention(d_dimensional_model = d_dimensional_model, num_heads = num_heads)\n",
    "    self.FFN = pointwise_feed_forward_network(d_dimensional_model, dff)\n",
    "\n",
    "    self.LayerNorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.LayerNorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "    attention_output, _ = self.MHA(x, x, x, mask) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n",
    "    attention_output = self.dropout1(attention_output, training = training)\n",
    "    output1 = self.LayerNorm1(x + attention_output) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n",
    "    FFN_output = self.FFN(output1) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n",
    "    FFN_output = self.dropout2(FFN_output, training = training)\n",
    "    output2 = self.LayerNorm2(output1 + FFN_output) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n",
    "    return output2\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, d_dimensional_model, num_heads, dff, dropout_rate = 0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "    self.MHA1 = MultiHeadAttention(d_dimensional_model = d_dimensional_model, num_heads = num_heads)\n",
    "    self.MHA2 = MultiHeadAttention(d_dimensional_model = d_dimensional_model, num_heads = num_heads)\n",
    "\n",
    "    self.FFN = pointwise_feed_forward_network(d_dimensional_model, dff)\n",
    "\n",
    "    self.LayerNorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.LayerNorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.LayerNorm3 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x, encoder_output, training, lookahead_mask, padding_mask):\n",
    "    '''\n",
    "    encoder_output.shape: (batch_size, input_sequence_len, d_dimensional_model)\n",
    "    '''\n",
    "    attention1, attention_weights_block1 = self.MHA1(x, x, x, lookahead_mask) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n",
    "    attention1 = self.dropout1(attention1, training = training)\n",
    "    output1 = self.LayerNorm1(attention1 + x)\n",
    "\n",
    "    attention2, attention_weights_block2 = self.MHA2(encoder_output, encoder_output, output1, padding_mask) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n",
    "    attention2 = self.dropout2(attention2, training = training)\n",
    "    output2 = self.LayerNorm2(attention2 + output1) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n",
    "\n",
    "    FFN_output = self.FFN(output2) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n",
    "    FFN_output = self.dropout3(FFN_output, training = training)\n",
    "    output3 = self.LayerNorm3(FFN_output + output2) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n",
    "    return output3, attention_weights_block1, attention_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y95ZyKOnbRFT"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_dimensional_model, num_heads, dff, input_vocab_size, dropout_rate = 0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.d_dimensional_model = d_dimensional_model\n",
    "    self.num_layers = num_layers\n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_dimensional_model)\n",
    "    self.positional_encoding = positional_encoding(128, self.d_dimensional_model)\n",
    "    self.encoder_layers = [EncoderLayer(d_dimensional_model = d_dimensional_model, num_heads = num_heads, dff = dff, dropout_rate = dropout_rate)\n",
    "    for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "    sequence_len = tf.shape(x)[1]\n",
    "    # Adding embedding and positional encoding\n",
    "    x = self.embedding(x) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_dimensional_model, tf.float32))\n",
    "    x += self.positional_encoding[:, :sequence_len, :]\n",
    "    x = self.dropout(x, training = training)\n",
    "    for j in range(self.num_layers):\n",
    "      x = self.encoder_layers[j](x, training, mask)\n",
    "    return x # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_dimensional_model, num_heads, dff, target_vocab_size, dropout_rate = 0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.d_dimensional_model = d_dimensional_model\n",
    "    self.num_layers = num_layers\n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_dimensional_model)\n",
    "    self.positional_encoding = positional_encoding(128, d_dimensional_model)\n",
    "    self.decoder_layers = [DecoderLayer(d_dimensional_model = d_dimensional_model, num_heads = num_heads, dff = dff, dropout_rate = dropout_rate)\n",
    "    for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x, encoder_output, training, lookahead_mask, padding_mask):\n",
    "    sequence_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    x = self.embedding(x) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_dimensional_model, tf.float32))\n",
    "    x += self.positional_encoding[:, :sequence_len, :]\n",
    "    x = self.dropout(x, training = training)\n",
    "\n",
    "    for k in range(self.num_layers):\n",
    "      x, block1, block2 = self.decoder_layers[k](x, encoder_output, training, lookahead_mask, padding_mask)\n",
    "      attention_weights['decoder_layer{}_block1'.format(k+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(k+1)] = block2\n",
    "    return x, attention_weights # x.shape: (batch_size, target_sequence_len, d_dimensional_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6dm6WYIFmTq"
   },
   "source": [
    "# **Defining The Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eddzm6A1FhGH"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_dimensional_model, num_heads, dff, input_vocab_size, target_vocab_size, dropout_rate = 0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers = num_layers, d_dimensional_model = d_dimensional_model, num_heads = num_heads, dff = dff,\n",
    "                           input_vocab_size = input_vocab_size, dropout_rate = dropout_rate)\n",
    "    self.decoder = Decoder(num_layers = num_layers, d_dimensional_model = d_dimensional_model, num_heads = num_heads, dff = dff,\n",
    "                           target_vocab_size = target_vocab_size, dropout_rate = dropout_rate)\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    input, target = inputs\n",
    "    encoder_padding_mask, lookahead_mask, decoder_padding_mask = self.create_masks(input, target)\n",
    "    encoder_output = self.encoder(input, training, encoder_padding_mask) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n",
    "    # decoder_output.shape: (batch_size, target_sequence_len, d_dimensional_model)\n",
    "    decoder_output, attention_weights = self.decoder(target, encoder_output, training, lookahead_mask, decoder_padding_mask)\n",
    "    final_output = self.final_layer(decoder_output) # Shape: (batch_size, target_sequence_len, target_vocab_size)\n",
    "    return final_output, attention_weights\n",
    "\n",
    "  def create_masks(self, input, target):\n",
    "    encoder_padding_mask = create_padding_mask(input)\n",
    "    # This padding mask is used in the second attention block of the decoder to mask out the encoder outputs\n",
    "    decoder_padding_mask = create_padding_mask(input)\n",
    "    # This lookahead mask is used in the first attention block of the decoder to pad and mask future tokens in the input received by the decoder\n",
    "    lookahead_mask = create_lookahead_mask(tf.shape(target)[1])\n",
    "    decoder_target_padding_mask = create_padding_mask(target)\n",
    "    lookahead_mask = tf.maximum(decoder_target_padding_mask, lookahead_mask)\n",
    "    return encoder_padding_mask, lookahead_mask, decoder_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAPeHy8VJWI3"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_dimensional_model, warmup_steps = 4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    self.d_dimensional_model = d_dimensional_model\n",
    "    self.d_dimensional_model = tf.cast(self.d_dimensional_model, tf.float32)\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** (-1.5))\n",
    "    return tf.math.rsqrt(self.d_dimensional_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = CustomSchedule(128)\n",
    "translation_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsfK2sOHLeXk"
   },
   "outputs": [],
   "source": [
    "def loss_function(actual, prediction):\n",
    "  mask = tf.math.logical_not(tf.math.equal(actual, 0))\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
    "  loss = loss_object(actual, prediction)\n",
    "  mask = tf.cast(mask, dtype = loss.dtype)\n",
    "  loss *= mask\n",
    "  return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "\n",
    "def accuracy_function(actual, prediction):\n",
    "  accuracies = tf.equal(actual, tf.argmax(prediction, axis = 2))\n",
    "  mask = tf.math.logical_not(tf.math.equal(actual, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype = tf.float32)\n",
    "  mask = tf.cast(mask, dtype = tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "training_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "training_accuracy = tf.keras.metrics.Mean(name = 'train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzDRb3YFNqdq"
   },
   "outputs": [],
   "source": [
    "translation_transformer = Transformer(num_layers = 4, d_dimensional_model = 128, num_heads = 8, dff = 512,\n",
    "                                      input_vocab_size = translation_tokenizers.pt.get_vocab_size().numpy(),\n",
    "                                      target_vocab_size = translation_tokenizers.en.get_vocab_size().numpy(), dropout_rate = 0.1)\n",
    "\n",
    "translation_checkpoint_path = 'Checkpoints/train'\n",
    "translation_checkpoint = tf.train.Checkpoint(transformer = translation_transformer, optimizer = translation_optimizer)\n",
    "translation_checkpoint_manager = tf.train.CheckpointManager(translation_checkpoint, translation_checkpoint_path, max_to_keep = 5)\n",
    "\n",
    "# If a checkpoint exists, restore the latest checkpoint\n",
    "if translation_checkpoint_manager.latest_checkpoint:\n",
    "  translation_checkpoint.restore(translation_checkpoint_manager.latest_checkpoint)\n",
    "  print('Latest checkpoint restored!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sm5j_hxR10n"
   },
   "outputs": [],
   "source": [
    "train_step_signature = [tf.TensorSpec(shape = (None, None), dtype = tf.int64), tf.TensorSpec(shape = (None, None), dtype = tf.int64)]\n",
    "\n",
    "@tf.function(input_signature = train_step_signature)\n",
    "def train_step(input, target):\n",
    "  target_input = target[:, :-1]\n",
    "  target_actual = target[:, 1:]\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = translation_transformer([input, target_input], training = True)\n",
    "    loss = loss_function(target_actual, predictions)\n",
    "  gradients = tape.gradient(loss, translation_transformer.trainable_variables)\n",
    "  translation_optimizer.apply_gradients(zip(gradients, translation_transformer.trainable_variables))\n",
    "  training_loss(loss)\n",
    "  training_accuracy(accuracy_function(target_actual, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKuKZAggF6rL"
   },
   "source": [
    "# **Training The Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1706944,
     "status": "ok",
     "timestamp": 1694582939884,
     "user": {
      "displayName": "Edwin Goh Duo Yao",
      "userId": "00967731948897399037"
     },
     "user_tz": -480
    },
    "id": "j4L1csXvTwX1",
    "outputId": "5699891b-8845-4fa5-8f5a-a9f16fdce890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0: Loss = 8.8896, Accuracy = 0.0000\n",
      "Epoch 1, Batch 50: Loss = 8.8225, Accuracy = 0.0012\n",
      "Epoch 1, Batch 100: Loss = 8.7163, Accuracy = 0.0229\n",
      "Epoch 1, Batch 150: Loss = 8.6014, Accuracy = 0.0353\n",
      "Epoch 1, Batch 200: Loss = 8.4596, Accuracy = 0.0417\n",
      "Epoch 1, Batch 250: Loss = 8.2898, Accuracy = 0.0466\n",
      "Epoch 1, Batch 300: Loss = 8.0973, Accuracy = 0.0524\n",
      "Epoch 1, Batch 350: Loss = 7.8965, Accuracy = 0.0607\n",
      "Epoch 1, Batch 400: Loss = 7.7058, Accuracy = 0.0687\n",
      "Epoch 1, Batch 450: Loss = 7.5375, Accuracy = 0.0754\n",
      "Epoch 1, Batch 500: Loss = 7.3899, Accuracy = 0.0815\n",
      "Epoch 1, Batch 550: Loss = 7.2555, Accuracy = 0.0883\n",
      "Epoch 1, Batch 600: Loss = 7.1323, Accuracy = 0.0955\n",
      "Epoch 1, Batch 650: Loss = 7.0171, Accuracy = 0.1024\n",
      "Epoch 1, Batch 700: Loss = 6.9101, Accuracy = 0.1088\n",
      "Epoch 2, Batch 0: Loss = 5.6769, Accuracy = 0.1845\n",
      "Epoch 2, Batch 50: Loss = 5.4008, Accuracy = 0.1988\n",
      "Epoch 2, Batch 100: Loss = 5.3558, Accuracy = 0.2005\n",
      "Epoch 2, Batch 150: Loss = 5.3169, Accuracy = 0.2036\n",
      "Epoch 2, Batch 200: Loss = 5.2841, Accuracy = 0.2067\n",
      "Epoch 2, Batch 250: Loss = 5.2595, Accuracy = 0.2097\n",
      "Epoch 2, Batch 300: Loss = 5.2366, Accuracy = 0.2119\n",
      "Epoch 2, Batch 350: Loss = 5.2051, Accuracy = 0.2156\n",
      "Epoch 2, Batch 400: Loss = 5.1853, Accuracy = 0.2178\n",
      "Epoch 2, Batch 450: Loss = 5.1580, Accuracy = 0.2203\n",
      "Epoch 2, Batch 500: Loss = 5.1341, Accuracy = 0.2228\n",
      "Epoch 2, Batch 550: Loss = 5.1113, Accuracy = 0.2252\n",
      "Epoch 2, Batch 600: Loss = 5.0885, Accuracy = 0.2273\n",
      "Epoch 2, Batch 650: Loss = 5.0660, Accuracy = 0.2296\n",
      "Epoch 3, Batch 0: Loss = 4.4578, Accuracy = 0.2832\n",
      "Epoch 3, Batch 50: Loss = 4.7168, Accuracy = 0.2638\n",
      "Epoch 3, Batch 100: Loss = 4.6948, Accuracy = 0.2650\n",
      "Epoch 3, Batch 150: Loss = 4.6901, Accuracy = 0.2647\n",
      "Epoch 3, Batch 200: Loss = 4.6690, Accuracy = 0.2664\n",
      "Epoch 3, Batch 250: Loss = 4.6545, Accuracy = 0.2676\n",
      "Epoch 3, Batch 300: Loss = 4.6427, Accuracy = 0.2686\n",
      "Epoch 3, Batch 350: Loss = 4.6250, Accuracy = 0.2703\n",
      "Epoch 3, Batch 400: Loss = 4.6127, Accuracy = 0.2716\n",
      "Epoch 3, Batch 450: Loss = 4.6003, Accuracy = 0.2728\n",
      "Epoch 3, Batch 500: Loss = 4.5827, Accuracy = 0.2746\n",
      "Epoch 3, Batch 550: Loss = 4.5676, Accuracy = 0.2762\n",
      "Epoch 3, Batch 600: Loss = 4.5563, Accuracy = 0.2775\n",
      "Epoch 3, Batch 650: Loss = 4.5435, Accuracy = 0.2789\n",
      "Epoch 4, Batch 0: Loss = 4.2364, Accuracy = 0.3115\n",
      "Epoch 4, Batch 50: Loss = 4.2522, Accuracy = 0.3109\n",
      "Epoch 4, Batch 100: Loss = 4.2079, Accuracy = 0.3162\n",
      "Epoch 4, Batch 150: Loss = 4.1912, Accuracy = 0.3182\n",
      "Epoch 4, Batch 200: Loss = 4.1778, Accuracy = 0.3190\n",
      "Epoch 4, Batch 250: Loss = 4.1689, Accuracy = 0.3202\n",
      "Epoch 4, Batch 300: Loss = 4.1514, Accuracy = 0.3228\n",
      "Epoch 4, Batch 350: Loss = 4.1376, Accuracy = 0.3246\n",
      "Epoch 4, Batch 400: Loss = 4.1209, Accuracy = 0.3268\n",
      "Epoch 4, Batch 450: Loss = 4.1041, Accuracy = 0.3292\n",
      "Epoch 4, Batch 500: Loss = 4.0857, Accuracy = 0.3314\n",
      "Epoch 4, Batch 550: Loss = 4.0698, Accuracy = 0.3334\n",
      "Epoch 4, Batch 600: Loss = 4.0574, Accuracy = 0.3351\n",
      "Epoch 4, Batch 650: Loss = 4.0428, Accuracy = 0.3369\n",
      "Epoch 4, Batch 700: Loss = 4.0271, Accuracy = 0.3390\n",
      "Epoch 5, Batch 0: Loss = 3.8613, Accuracy = 0.3511\n",
      "Epoch 5, Batch 50: Loss = 3.7514, Accuracy = 0.3694\n",
      "Epoch 5, Batch 100: Loss = 3.7255, Accuracy = 0.3733\n",
      "Epoch 5, Batch 150: Loss = 3.7052, Accuracy = 0.3764\n",
      "Epoch 5, Batch 200: Loss = 3.6987, Accuracy = 0.3775\n",
      "Epoch 5, Batch 250: Loss = 3.6819, Accuracy = 0.3798\n",
      "Epoch 5, Batch 300: Loss = 3.6704, Accuracy = 0.3814\n",
      "Epoch 5, Batch 350: Loss = 3.6588, Accuracy = 0.3829\n",
      "Epoch 5, Batch 400: Loss = 3.6439, Accuracy = 0.3847\n",
      "Epoch 5, Batch 450: Loss = 3.6333, Accuracy = 0.3859\n",
      "Epoch 5, Batch 500: Loss = 3.6177, Accuracy = 0.3879\n",
      "Epoch 5, Batch 550: Loss = 3.6027, Accuracy = 0.3900\n",
      "Epoch 5, Batch 600: Loss = 3.5917, Accuracy = 0.3913\n",
      "Epoch 5, Batch 650: Loss = 3.5833, Accuracy = 0.3927\n",
      "Saving checkpoint for epoch 5 at Checkpoints/train/ckpt-1\n",
      "Epoch 5: Loss = 3.5717, Accuracy = 0.3941\n",
      "Time taken to complete 1 epoch: 80.15s\n",
      "\n",
      "Epoch 6, Batch 0: Loss = 3.4539, Accuracy = 0.3926\n",
      "Epoch 6, Batch 50: Loss = 3.3351, Accuracy = 0.4195\n",
      "Epoch 6, Batch 100: Loss = 3.3065, Accuracy = 0.4235\n",
      "Epoch 6, Batch 150: Loss = 3.2953, Accuracy = 0.4253\n",
      "Epoch 6, Batch 200: Loss = 3.2890, Accuracy = 0.4265\n",
      "Epoch 6, Batch 250: Loss = 3.2785, Accuracy = 0.4282\n",
      "Epoch 6, Batch 300: Loss = 3.2762, Accuracy = 0.4287\n",
      "Epoch 6, Batch 350: Loss = 3.2669, Accuracy = 0.4299\n",
      "Epoch 6, Batch 400: Loss = 3.2586, Accuracy = 0.4314\n",
      "Epoch 6, Batch 450: Loss = 3.2516, Accuracy = 0.4325\n",
      "Epoch 6, Batch 500: Loss = 3.2479, Accuracy = 0.4330\n",
      "Epoch 6, Batch 550: Loss = 3.2429, Accuracy = 0.4338\n",
      "Epoch 6, Batch 600: Loss = 3.2359, Accuracy = 0.4348\n",
      "Epoch 6, Batch 650: Loss = 3.2266, Accuracy = 0.4361\n",
      "Epoch 7, Batch 0: Loss = 2.8944, Accuracy = 0.4900\n",
      "Epoch 7, Batch 50: Loss = 3.0027, Accuracy = 0.4612\n",
      "Epoch 7, Batch 100: Loss = 2.9695, Accuracy = 0.4657\n",
      "Epoch 7, Batch 150: Loss = 2.9628, Accuracy = 0.4669\n",
      "Epoch 7, Batch 200: Loss = 2.9603, Accuracy = 0.4674\n",
      "Epoch 7, Batch 250: Loss = 2.9497, Accuracy = 0.4692\n",
      "Epoch 7, Batch 300: Loss = 2.9390, Accuracy = 0.4702\n",
      "Epoch 7, Batch 350: Loss = 2.9316, Accuracy = 0.4711\n",
      "Epoch 7, Batch 400: Loss = 2.9241, Accuracy = 0.4722\n",
      "Epoch 7, Batch 450: Loss = 2.9205, Accuracy = 0.4727\n",
      "Epoch 7, Batch 500: Loss = 2.9122, Accuracy = 0.4740\n",
      "Epoch 7, Batch 550: Loss = 2.9048, Accuracy = 0.4754\n",
      "Epoch 7, Batch 600: Loss = 2.8990, Accuracy = 0.4763\n",
      "Epoch 7, Batch 650: Loss = 2.8957, Accuracy = 0.4769\n",
      "Epoch 7, Batch 700: Loss = 2.8893, Accuracy = 0.4779\n",
      "Epoch 8, Batch 0: Loss = 2.5528, Accuracy = 0.5245\n",
      "Epoch 8, Batch 50: Loss = 2.6389, Accuracy = 0.5092\n",
      "Epoch 8, Batch 100: Loss = 2.6416, Accuracy = 0.5092\n",
      "Epoch 8, Batch 150: Loss = 2.6359, Accuracy = 0.5096\n",
      "Epoch 8, Batch 200: Loss = 2.6440, Accuracy = 0.5085\n",
      "Epoch 8, Batch 250: Loss = 2.6389, Accuracy = 0.5095\n",
      "Epoch 8, Batch 300: Loss = 2.6373, Accuracy = 0.5097\n",
      "Epoch 8, Batch 350: Loss = 2.6292, Accuracy = 0.5111\n",
      "Epoch 8, Batch 400: Loss = 2.6247, Accuracy = 0.5119\n",
      "Epoch 8, Batch 450: Loss = 2.6225, Accuracy = 0.5121\n",
      "Epoch 8, Batch 500: Loss = 2.6188, Accuracy = 0.5127\n",
      "Epoch 8, Batch 550: Loss = 2.6161, Accuracy = 0.5131\n",
      "Epoch 8, Batch 600: Loss = 2.6131, Accuracy = 0.5136\n",
      "Epoch 8, Batch 650: Loss = 2.6122, Accuracy = 0.5141\n",
      "Epoch 8, Batch 700: Loss = 2.6091, Accuracy = 0.5146\n",
      "Epoch 9, Batch 0: Loss = 2.3304, Accuracy = 0.5537\n",
      "Epoch 9, Batch 50: Loss = 2.4259, Accuracy = 0.5373\n",
      "Epoch 9, Batch 100: Loss = 2.4242, Accuracy = 0.5384\n",
      "Epoch 9, Batch 150: Loss = 2.4232, Accuracy = 0.5388\n",
      "Epoch 9, Batch 200: Loss = 2.4177, Accuracy = 0.5400\n",
      "Epoch 9, Batch 250: Loss = 2.4221, Accuracy = 0.5395\n",
      "Epoch 9, Batch 300: Loss = 2.4219, Accuracy = 0.5388\n",
      "Epoch 9, Batch 350: Loss = 2.4215, Accuracy = 0.5388\n",
      "Epoch 9, Batch 400: Loss = 2.4161, Accuracy = 0.5395\n",
      "Epoch 9, Batch 450: Loss = 2.4113, Accuracy = 0.5405\n",
      "Epoch 9, Batch 500: Loss = 2.4091, Accuracy = 0.5408\n",
      "Epoch 9, Batch 550: Loss = 2.4105, Accuracy = 0.5405\n",
      "Epoch 9, Batch 600: Loss = 2.4068, Accuracy = 0.5411\n",
      "Epoch 9, Batch 650: Loss = 2.4062, Accuracy = 0.5415\n",
      "Epoch 9, Batch 700: Loss = 2.4071, Accuracy = 0.5416\n",
      "Epoch 10, Batch 0: Loss = 2.3411, Accuracy = 0.5385\n",
      "Epoch 10, Batch 50: Loss = 2.2501, Accuracy = 0.5641\n",
      "Epoch 10, Batch 100: Loss = 2.2483, Accuracy = 0.5628\n",
      "Epoch 10, Batch 150: Loss = 2.2326, Accuracy = 0.5645\n",
      "Epoch 10, Batch 200: Loss = 2.2429, Accuracy = 0.5631\n",
      "Epoch 10, Batch 250: Loss = 2.2430, Accuracy = 0.5630\n",
      "Epoch 10, Batch 300: Loss = 2.2454, Accuracy = 0.5628\n",
      "Epoch 10, Batch 350: Loss = 2.2440, Accuracy = 0.5635\n",
      "Epoch 10, Batch 400: Loss = 2.2429, Accuracy = 0.5635\n",
      "Epoch 10, Batch 450: Loss = 2.2448, Accuracy = 0.5632\n",
      "Epoch 10, Batch 500: Loss = 2.2437, Accuracy = 0.5636\n",
      "Epoch 10, Batch 550: Loss = 2.2445, Accuracy = 0.5636\n",
      "Epoch 10, Batch 600: Loss = 2.2445, Accuracy = 0.5638\n",
      "Epoch 10, Batch 650: Loss = 2.2455, Accuracy = 0.5637\n",
      "Saving checkpoint for epoch 10 at Checkpoints/train/ckpt-2\n",
      "Epoch 10: Loss = 2.2464, Accuracy = 0.5637\n",
      "Time taken to complete 1 epoch: 75.91s\n",
      "\n",
      "Epoch 11, Batch 0: Loss = 2.1877, Accuracy = 0.5663\n",
      "Epoch 11, Batch 50: Loss = 2.1172, Accuracy = 0.5813\n",
      "Epoch 11, Batch 100: Loss = 2.1160, Accuracy = 0.5803\n",
      "Epoch 11, Batch 150: Loss = 2.1175, Accuracy = 0.5806\n",
      "Epoch 11, Batch 200: Loss = 2.1083, Accuracy = 0.5823\n",
      "Epoch 11, Batch 250: Loss = 2.1108, Accuracy = 0.5820\n",
      "Epoch 11, Batch 300: Loss = 2.1137, Accuracy = 0.5818\n",
      "Epoch 11, Batch 350: Loss = 2.1188, Accuracy = 0.5809\n",
      "Epoch 11, Batch 400: Loss = 2.1189, Accuracy = 0.5808\n",
      "Epoch 11, Batch 450: Loss = 2.1199, Accuracy = 0.5808\n",
      "Epoch 11, Batch 500: Loss = 2.1194, Accuracy = 0.5810\n",
      "Epoch 11, Batch 550: Loss = 2.1192, Accuracy = 0.5811\n",
      "Epoch 11, Batch 600: Loss = 2.1193, Accuracy = 0.5813\n",
      "Epoch 11, Batch 650: Loss = 2.1210, Accuracy = 0.5811\n",
      "Epoch 11, Batch 700: Loss = 2.1199, Accuracy = 0.5816\n",
      "Epoch 12, Batch 0: Loss = 2.0620, Accuracy = 0.5942\n",
      "Epoch 12, Batch 50: Loss = 2.0041, Accuracy = 0.5964\n",
      "Epoch 12, Batch 100: Loss = 1.9875, Accuracy = 0.5995\n",
      "Epoch 12, Batch 150: Loss = 1.9872, Accuracy = 0.5998\n",
      "Epoch 12, Batch 200: Loss = 1.9894, Accuracy = 0.5995\n",
      "Epoch 12, Batch 250: Loss = 1.9941, Accuracy = 0.5990\n",
      "Epoch 12, Batch 300: Loss = 1.9973, Accuracy = 0.5985\n",
      "Epoch 12, Batch 350: Loss = 1.9990, Accuracy = 0.5980\n",
      "Epoch 12, Batch 400: Loss = 2.0009, Accuracy = 0.5975\n",
      "Epoch 12, Batch 450: Loss = 2.0002, Accuracy = 0.5978\n",
      "Epoch 12, Batch 500: Loss = 2.0030, Accuracy = 0.5975\n",
      "Epoch 12, Batch 550: Loss = 2.0032, Accuracy = 0.5975\n",
      "Epoch 12, Batch 600: Loss = 2.0049, Accuracy = 0.5974\n",
      "Epoch 12, Batch 650: Loss = 2.0058, Accuracy = 0.5973\n",
      "Epoch 12, Batch 700: Loss = 2.0070, Accuracy = 0.5973\n",
      "Epoch 13, Batch 0: Loss = 1.7758, Accuracy = 0.6195\n",
      "Epoch 13, Batch 50: Loss = 1.8767, Accuracy = 0.6141\n",
      "Epoch 13, Batch 100: Loss = 1.8901, Accuracy = 0.6136\n",
      "Epoch 13, Batch 150: Loss = 1.8955, Accuracy = 0.6127\n",
      "Epoch 13, Batch 200: Loss = 1.9005, Accuracy = 0.6112\n",
      "Epoch 13, Batch 250: Loss = 1.9032, Accuracy = 0.6109\n",
      "Epoch 13, Batch 300: Loss = 1.9040, Accuracy = 0.6109\n",
      "Epoch 13, Batch 350: Loss = 1.9051, Accuracy = 0.6110\n",
      "Epoch 13, Batch 400: Loss = 1.9104, Accuracy = 0.6104\n",
      "Epoch 13, Batch 450: Loss = 1.9121, Accuracy = 0.6103\n",
      "Epoch 13, Batch 500: Loss = 1.9124, Accuracy = 0.6103\n",
      "Epoch 13, Batch 550: Loss = 1.9138, Accuracy = 0.6102\n",
      "Epoch 13, Batch 600: Loss = 1.9144, Accuracy = 0.6104\n",
      "Epoch 13, Batch 650: Loss = 1.9154, Accuracy = 0.6105\n",
      "Epoch 13, Batch 700: Loss = 1.9171, Accuracy = 0.6104\n",
      "Epoch 14, Batch 0: Loss = 1.6960, Accuracy = 0.6466\n",
      "Epoch 14, Batch 50: Loss = 1.8020, Accuracy = 0.6274\n",
      "Epoch 14, Batch 100: Loss = 1.8079, Accuracy = 0.6264\n",
      "Epoch 14, Batch 150: Loss = 1.8072, Accuracy = 0.6267\n",
      "Epoch 14, Batch 200: Loss = 1.8122, Accuracy = 0.6256\n",
      "Epoch 14, Batch 250: Loss = 1.8111, Accuracy = 0.6257\n",
      "Epoch 14, Batch 300: Loss = 1.8132, Accuracy = 0.6255\n",
      "Epoch 14, Batch 350: Loss = 1.8171, Accuracy = 0.6250\n",
      "Epoch 14, Batch 400: Loss = 1.8217, Accuracy = 0.6242\n",
      "Epoch 14, Batch 450: Loss = 1.8229, Accuracy = 0.6242\n",
      "Epoch 14, Batch 500: Loss = 1.8251, Accuracy = 0.6237\n",
      "Epoch 14, Batch 550: Loss = 1.8275, Accuracy = 0.6233\n",
      "Epoch 14, Batch 600: Loss = 1.8316, Accuracy = 0.6228\n",
      "Epoch 14, Batch 650: Loss = 1.8360, Accuracy = 0.6222\n",
      "Epoch 15, Batch 0: Loss = 1.9272, Accuracy = 0.6017\n",
      "Epoch 15, Batch 50: Loss = 1.7216, Accuracy = 0.6416\n",
      "Epoch 15, Batch 100: Loss = 1.7217, Accuracy = 0.6414\n",
      "Epoch 15, Batch 150: Loss = 1.7256, Accuracy = 0.6400\n",
      "Epoch 15, Batch 200: Loss = 1.7318, Accuracy = 0.6386\n",
      "Epoch 15, Batch 250: Loss = 1.7385, Accuracy = 0.6371\n",
      "Epoch 15, Batch 300: Loss = 1.7431, Accuracy = 0.6366\n",
      "Epoch 15, Batch 350: Loss = 1.7504, Accuracy = 0.6355\n",
      "Epoch 15, Batch 400: Loss = 1.7495, Accuracy = 0.6355\n",
      "Epoch 15, Batch 450: Loss = 1.7546, Accuracy = 0.6344\n",
      "Epoch 15, Batch 500: Loss = 1.7594, Accuracy = 0.6338\n",
      "Epoch 15, Batch 550: Loss = 1.7613, Accuracy = 0.6335\n",
      "Epoch 15, Batch 600: Loss = 1.7648, Accuracy = 0.6331\n",
      "Epoch 15, Batch 650: Loss = 1.7687, Accuracy = 0.6326\n",
      "Saving checkpoint for epoch 15 at Checkpoints/train/ckpt-3\n",
      "Epoch 15: Loss = 1.7717, Accuracy = 0.6321\n",
      "Time taken to complete 1 epoch: 76.26s\n",
      "\n",
      "Epoch 16, Batch 0: Loss = 1.8738, Accuracy = 0.6215\n",
      "Epoch 16, Batch 50: Loss = 1.6611, Accuracy = 0.6474\n",
      "Epoch 16, Batch 100: Loss = 1.6582, Accuracy = 0.6481\n",
      "Epoch 16, Batch 150: Loss = 1.6703, Accuracy = 0.6459\n",
      "Epoch 16, Batch 200: Loss = 1.6838, Accuracy = 0.6434\n",
      "Epoch 16, Batch 250: Loss = 1.6826, Accuracy = 0.6440\n",
      "Epoch 16, Batch 300: Loss = 1.6837, Accuracy = 0.6438\n",
      "Epoch 16, Batch 350: Loss = 1.6872, Accuracy = 0.6435\n",
      "Epoch 16, Batch 400: Loss = 1.6905, Accuracy = 0.6434\n",
      "Epoch 16, Batch 450: Loss = 1.6949, Accuracy = 0.6426\n",
      "Epoch 16, Batch 500: Loss = 1.7012, Accuracy = 0.6416\n",
      "Epoch 16, Batch 550: Loss = 1.7059, Accuracy = 0.6410\n",
      "Epoch 16, Batch 600: Loss = 1.7080, Accuracy = 0.6408\n",
      "Epoch 16, Batch 650: Loss = 1.7104, Accuracy = 0.6404\n",
      "Epoch 17, Batch 0: Loss = 1.6997, Accuracy = 0.6300\n",
      "Epoch 17, Batch 50: Loss = 1.6064, Accuracy = 0.6563\n",
      "Epoch 17, Batch 100: Loss = 1.6099, Accuracy = 0.6569\n",
      "Epoch 17, Batch 150: Loss = 1.6192, Accuracy = 0.6546\n",
      "Epoch 17, Batch 200: Loss = 1.6267, Accuracy = 0.6533\n",
      "Epoch 17, Batch 250: Loss = 1.6303, Accuracy = 0.6528\n",
      "Epoch 17, Batch 300: Loss = 1.6353, Accuracy = 0.6522\n",
      "Epoch 17, Batch 350: Loss = 1.6406, Accuracy = 0.6511\n",
      "Epoch 17, Batch 400: Loss = 1.6416, Accuracy = 0.6508\n",
      "Epoch 17, Batch 450: Loss = 1.6454, Accuracy = 0.6504\n",
      "Epoch 17, Batch 500: Loss = 1.6488, Accuracy = 0.6499\n",
      "Epoch 17, Batch 550: Loss = 1.6510, Accuracy = 0.6498\n",
      "Epoch 17, Batch 600: Loss = 1.6528, Accuracy = 0.6495\n",
      "Epoch 17, Batch 650: Loss = 1.6549, Accuracy = 0.6495\n",
      "Epoch 17, Batch 700: Loss = 1.6580, Accuracy = 0.6492\n",
      "Epoch 18, Batch 0: Loss = 1.6114, Accuracy = 0.6550\n",
      "Epoch 18, Batch 50: Loss = 1.5745, Accuracy = 0.6607\n",
      "Epoch 18, Batch 100: Loss = 1.5720, Accuracy = 0.6608\n",
      "Epoch 18, Batch 150: Loss = 1.5708, Accuracy = 0.6617\n",
      "Epoch 18, Batch 200: Loss = 1.5762, Accuracy = 0.6610\n",
      "Epoch 18, Batch 250: Loss = 1.5826, Accuracy = 0.6597\n",
      "Epoch 18, Batch 300: Loss = 1.5857, Accuracy = 0.6596\n",
      "Epoch 18, Batch 350: Loss = 1.5875, Accuracy = 0.6591\n",
      "Epoch 18, Batch 400: Loss = 1.5924, Accuracy = 0.6587\n",
      "Epoch 18, Batch 450: Loss = 1.5945, Accuracy = 0.6583\n",
      "Epoch 18, Batch 500: Loss = 1.5961, Accuracy = 0.6580\n",
      "Epoch 18, Batch 550: Loss = 1.5995, Accuracy = 0.6574\n",
      "Epoch 18, Batch 600: Loss = 1.6007, Accuracy = 0.6571\n",
      "Epoch 18, Batch 650: Loss = 1.6043, Accuracy = 0.6566\n",
      "Epoch 18, Batch 700: Loss = 1.6070, Accuracy = 0.6564\n",
      "Epoch 19, Batch 0: Loss = 1.5398, Accuracy = 0.6654\n",
      "Epoch 19, Batch 50: Loss = 1.5057, Accuracy = 0.6718\n",
      "Epoch 19, Batch 100: Loss = 1.5114, Accuracy = 0.6714\n",
      "Epoch 19, Batch 150: Loss = 1.5132, Accuracy = 0.6709\n",
      "Epoch 19, Batch 200: Loss = 1.5274, Accuracy = 0.6689\n",
      "Epoch 19, Batch 250: Loss = 1.5274, Accuracy = 0.6688\n",
      "Epoch 19, Batch 300: Loss = 1.5332, Accuracy = 0.6681\n",
      "Epoch 19, Batch 350: Loss = 1.5383, Accuracy = 0.6673\n",
      "Epoch 19, Batch 400: Loss = 1.5409, Accuracy = 0.6668\n",
      "Epoch 19, Batch 450: Loss = 1.5420, Accuracy = 0.6667\n",
      "Epoch 19, Batch 500: Loss = 1.5463, Accuracy = 0.6660\n",
      "Epoch 19, Batch 550: Loss = 1.5509, Accuracy = 0.6654\n",
      "Epoch 19, Batch 600: Loss = 1.5553, Accuracy = 0.6648\n",
      "Epoch 19, Batch 650: Loss = 1.5583, Accuracy = 0.6644\n",
      "Epoch 20, Batch 0: Loss = 1.4780, Accuracy = 0.6743\n",
      "Epoch 20, Batch 50: Loss = 1.4760, Accuracy = 0.6743\n",
      "Epoch 20, Batch 100: Loss = 1.4812, Accuracy = 0.6752\n",
      "Epoch 20, Batch 150: Loss = 1.4831, Accuracy = 0.6745\n",
      "Epoch 20, Batch 200: Loss = 1.4872, Accuracy = 0.6738\n",
      "Epoch 20, Batch 250: Loss = 1.4906, Accuracy = 0.6736\n",
      "Epoch 20, Batch 300: Loss = 1.4943, Accuracy = 0.6734\n",
      "Epoch 20, Batch 350: Loss = 1.4996, Accuracy = 0.6723\n",
      "Epoch 20, Batch 400: Loss = 1.5023, Accuracy = 0.6722\n",
      "Epoch 20, Batch 450: Loss = 1.5032, Accuracy = 0.6720\n",
      "Epoch 20, Batch 500: Loss = 1.5088, Accuracy = 0.6711\n",
      "Epoch 20, Batch 550: Loss = 1.5131, Accuracy = 0.6704\n",
      "Epoch 20, Batch 600: Loss = 1.5166, Accuracy = 0.6698\n",
      "Epoch 20, Batch 650: Loss = 1.5196, Accuracy = 0.6694\n",
      "Saving checkpoint for epoch 20 at Checkpoints/train/ckpt-4\n",
      "Epoch 20: Loss = 1.5243, Accuracy = 0.6688\n",
      "Time taken to complete 1 epoch: 75.13s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "  start = time.perf_counter()\n",
    "  training_loss.reset_states()\n",
    "  training_accuracy.reset_states()\n",
    "\n",
    "  # Input: Portuguese; Target: English\n",
    "  for batch, (input, target) in enumerate(translation_training_batches):\n",
    "    train_step(input, target)\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "      print('Epoch {}, Batch {}: Loss = {:.4f}, Accuracy = {:.4f}'.format(epoch + 1, batch, training_loss.result(), training_accuracy.result()))\n",
    "\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    checkpoint_save_path = translation_checkpoint_manager.save()\n",
    "    print('Saving checkpoint for epoch {} at {}'.format(epoch + 1, checkpoint_save_path))\n",
    "    print('Epoch {}: Loss = {:.4f}, Accuracy = {:.4f}'.format(epoch + 1, training_loss.result(), training_accuracy.result()))\n",
    "    print('Time taken to complete 1 epoch: {:.2f}s\\n'.format(time.perf_counter() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLkxsCrBAG8b"
   },
   "source": [
    "# **Translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztzmDt_k9IwU"
   },
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "  def __init__(self, tokenizers, transformer):\n",
    "    self.tokenizers = tokenizers\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length = 128):\n",
    "    # Adding the start and end tokens since the input sentence is Portuguese\n",
    "    assert isinstance(sentence, tf.Tensor)\n",
    "    if len(sentence.shape) == 0:\n",
    "      sentence = sentence[tf.newaxis]\n",
    "    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
    "    encoder_input = sentence\n",
    "    # Initialize the output with the English start token since English is the output language\n",
    "    start_end = self.tokenizers.en.tokenize([''])[0]\n",
    "    start = start_end[0][tf.newaxis]\n",
    "    end = start_end[1][tf.newaxis]\n",
    "    # A 'tf.TensorArray' is required here, instead of a Python list' to ensure that dynamic-loop is traceable by 'tf.function'\n",
    "    output_array = tf.TensorArray(dtype = tf.int64, size = 0, dynamic_size = True).write(0, start)\n",
    "\n",
    "    for a in tf.range(max_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions, _ = self.transformer([encoder_input, output], training = False)\n",
    "      # Select the last token from the sequence_len dimension\n",
    "      predictions = predictions[:, -1:, :] # Shape: (batch_size, 1, vocab_size)\n",
    "      prediction_id = tf.argmax(predictions, axis = -1)\n",
    "      # Concatenate the prediction_id to the output which will be the decoder input\n",
    "      output_array = output_array.write(a + 1, prediction_id[0])\n",
    "      if prediction_id == end:\n",
    "        break\n",
    "    output = tf.transpose(output_array.stack()) # Shape: (1, tokens)\n",
    "    text = self.tokenizers.en.detokenize(output)[0]\n",
    "    tokens = self.tokenizers.en.lookup(output)[0]\n",
    "    # 'tf.function' prevents the use of attention weights that were calculated during the last iteration, hence they need to be recalculated outside of the loop\n",
    "    _, attention_weights = self.transformer([encoder_input, output[:, :-1]], training = False)\n",
    "    return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3585,
     "status": "ok",
     "timestamp": 1694584955680,
     "user": {
      "displayName": "Edwin Goh Duo Yao",
      "userId": "00967731948897399037"
     },
     "user_tz": -480
    },
    "id": "W5g6lUmJGyRk",
    "outputId": "6c27f794-173c-4f1e-da0a-1ff98ef6f2cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Prediction: my neighbors have heard about this idea .\n",
      "Ground truth: and my neighbouring homes heard about this idea.\n"
     ]
    }
   ],
   "source": [
    "translator = Translator(translation_tokenizers, translation_transformer)\n",
    "\n",
    "def translation_printer(sentence, tokens, ground_truth):\n",
    "  print('Input: {:15s}'.format(sentence))\n",
    "  print('Prediction: {:15s}'.format(tokens.numpy().decode('utf-8')))\n",
    "  print('Ground truth: {:15s}'.format(ground_truth))\n",
    "\n",
    "input_sentence = 'os meus vizinhos ouviram sobre esta ideia.'\n",
    "ground_truth = 'and my neighbouring homes heard about this idea.'\n",
    "translated_text, translated_tokens, attention_weights = translator(tf.constant(input_sentence))\n",
    "translation_printer(input_sentence, translated_text, ground_truth)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPNKm6dawmZlRItbwxjoErb",
   "mount_file_id": "1b3a0kuHH2Ptdv3sLl7gQAqn0r79yrUEF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
