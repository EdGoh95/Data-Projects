{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15448,"status":"ok","timestamp":1694581223575,"user":{"displayName":"Edwin Goh Duo Yao","userId":"00967731948897399037"},"user_tz":-480},"id":"sGVaYwgXVbhe","outputId":"9f0456f9-55d7-4fad-9136-646c45a5b1f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.10/dist-packages (4.9.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.4.0)\n","Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.4.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (8.1.7)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.1.8)\n","Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.23.5)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.3)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (3.20.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (5.9.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.31.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.14.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.3.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.10.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (4.66.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.15.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (6.0.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (4.5.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.16.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2023.7.22)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow_datasets) (1.16.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.60.0)\n","Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (2.13.0)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (0.14.0)\n","Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (2.13.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.57.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.9.0)\n","Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (16.0.6)\n","Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.16.0)\n","Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.0)\n","Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.3.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.33.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.3.7)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.2.2)\n"]}],"source":["!pip install tensorflow_datasets\n","!pip install tensorflow-text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_7VxZ3gWBeW"},"outputs":[],"source":["import logging\n","import os\n","import time\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_text\n","import tensorflow_datasets as tfds\n","# Suppress warnings\n","logging.getLogger('tensorflow').setLevel(logging.ERROR)"]},{"cell_type":"markdown","metadata":{"id":"HgxSSLlEmbQs"},"source":["# **Loading The Portuguse To English Translation Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUwHnW3aXkTd"},"outputs":[],"source":["translation_examples, translation_metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info = True, as_supervised = True)\n","translation_training_examples, translation_validation_examples = translation_examples['train'], translation_examples['validation']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxqGrnnOYlQC","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1694581230612,"user_tz":-480,"elapsed":4,"user":{"displayName":"Edwin Goh Duo Yao","userId":"00967731948897399037"}},"outputId":"6bda969c-99a7-4169-97e1-a1c3418fc75a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'./Data/ted_hrlr_translate_pt_en_converter.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["tf.keras.utils.get_file('ted_hrlr_translate_pt_en_converter.zip',\n","                        'https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip', cache_dir = '.',\n","                        cache_subdir = 'Data', extract = True)"]},{"cell_type":"markdown","metadata":{"id":"aHnJ7SdGmrjV"},"source":["# **Exploring The Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SkXjTX5GeWph","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694581231353,"user_tz":-480,"elapsed":744,"user":{"displayName":"Edwin Goh Duo Yao","userId":"00967731948897399037"}},"outputId":"c4c87d57-1c62-40b8-ffc2-e58aaff3666c"},"outputs":[{"output_type":"stream","name":"stdout","text":["> Examples in Portuguese\n","e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n","mas e se estes fatores fossem ativos ?\n","mas eles não tinham a curiosidade de me testar .\n","> Examples in English\n","and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n","but what if it were active ?\n","but they did n't test for curiosity .\n"]}],"source":["translation_tokenizers = tf.saved_model.load('Data/ted_hrlr_translate_pt_en_converter')\n","for portuguese_examples, english_examples in translation_training_examples.batch(3).take(1):\n","  print('> Examples in Portuguese')\n","  for pt in portuguese_examples.numpy():\n","    print(pt.decode('utf-8'))\n","  print('> Examples in English')\n","  for en in english_examples.numpy():\n","    print(en.decode('utf-8'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iUPKqg5nfJrH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694581232101,"user_tz":-480,"elapsed":749,"user":{"displayName":"Edwin Goh Duo Yao","userId":"00967731948897399037"}},"outputId":"cf3d48cb-5181-4da2-cf59-db73ff134e60"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]\n","[2, 87, 90, 107, 76, 129, 1852, 30, 3]\n","[2, 87, 83, 149, 50, 9, 56, 664, 85, 2512, 15, 3]\n"]}],"source":["english_tokenizer_encoded = translation_tokenizers.en.tokenize(english_examples)\n","for row in english_tokenizer_encoded.to_list():\n","  print(row)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28vWllqvgTOs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694581232101,"user_tz":-480,"elapsed":4,"user":{"displayName":"Edwin Goh Duo Yao","userId":"00967731948897399037"}},"outputId":"1ae3d040-7378-4979-975c-6c701dbe2347"},"outputs":[{"output_type":"stream","name":"stdout","text":["and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n","but what if it were active ?\n","but they did n ' t test for curiosity .\n"]}],"source":["english_tokenizer_decoded = translation_tokenizers.en.detokenize(english_tokenizer_encoded)\n","for line in english_tokenizer_decoded.numpy():\n","  print(line.decode('utf-8'))"]},{"cell_type":"markdown","metadata":{"id":"UrnQXEWJmTJX"},"source":["# **Creating The Input Pipeline**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fm-LKemphg4S"},"outputs":[],"source":["def filter_max_tokens(pt_example, en_example):\n","  num_tokens = tf.maximum(tf.shape(pt_example)[1], tf.shape(en_example)[1])\n","  return num_tokens < 128\n","\n","def tokenize_pairs(pt_example, en_example):\n","  pt_example = translation_tokenizers.pt.tokenize(pt_example)\n","  # Convert to dense tensor, padded with zeros\n","  pt_example = pt_example.to_tensor()\n","\n","  en_example = translation_tokenizers.en.tokenize(en_example)\n","  # Convert to dense tensor, padded with zeros\n","  en_example = en_example.to_tensor()\n","  return pt_example, en_example\n","\n","def make_batches(ds):\n","  return ds.cache().shuffle(20000).batch(64).map(tokenize_pairs, num_parallel_calls = tf.data.AUTOTUNE).filter(filter_max_tokens).prefetch(tf.data.AUTOTUNE)\n","\n","translation_training_batches = make_batches(translation_training_examples)\n","translation_validation_batches = make_batches(translation_validation_examples)"]},{"cell_type":"markdown","metadata":{"id":"-BVTS6dZmxQ0"},"source":["# Adding The Positional Encodings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlqBAyxMm9m8"},"outputs":[],"source":["def get_angles(position, i, d_dimensional_model):\n","  angle_rates = 1/np.power(10000, (2*(i//2))/np.float32(d_dimensional_model))\n","  return position * angle_rates\n","\n","def positional_encoding(position, d_dimensional_model):\n","  angle_radians = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_dimensional_model)[np.newaxis, :], d_dimensional_model)\n","  # For every even element in the array (2i)\n","  angle_radians[:, 0::2] = np.sin(angle_radians[:, 0::2])\n","  # For every odd element in the array (2i+1)\n","  angle_radians[:, 1::2] = np.cos(angle_radians[:, 1::2])\n","  return tf.cast(angle_radians[np.newaxis, ...], dtype = tf.float32)"]},{"cell_type":"markdown","metadata":{"id":"q7Ry3lY8p4NE"},"source":["# **Look-Ahead Mask - Masking Future Tokens In A Sequence**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVN2CJQVqB0e"},"outputs":[],"source":["def create_padding_mask(sequence):\n","  '''\n","  Adding extra dimensions for the additional padding in the attention logits\n","  '''\n","  sequence = tf.cast(tf.math.equal(sequence, 0), tf.float32)\n","  return sequence[:, tf.newaxis, tf.newaxis, :] # (batch_size, 1, 1, sequence_len)\n","\n","def create_lookahead_mask(size):\n","  return 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0) # (sequence_len, sequence_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7hB8CYH8uSc4"},"outputs":[],"source":["def scaled_dot_product_attention(q, k, v, mask = None):\n","  '''\n","  Calculates the attention weights. Returns both output and attention weights\n","  Args\n","    q : query shape == (..., sequence_len_q, depth_q)\n","    k : key shape == (..., sequence_len_k, depth_k)\n","    v : value shape == (..., sequence_len_v, depth_v)\n","    mask : Float tensor with shape that is broadcastable to (..., sequence_len_q, sequence_len_k). Default = None\n","  q, k, v : Must have matching leading dimensions\n","  k, v : Must have matching penultimate dimension (sequence_len_k == sequence_len_v)\n","  mask : Has different shapes depending on its type (padding/look-ahead) but it must be broadcastable for addition\n","  '''\n","  qk_matmul = tf.matmul(q, k, transpose_b = True) # output_shape = (..., sequence_len_q, sequence_len_k)\n","  scaled_attention_logits = qk_matmul/tf.math.sqrt(tf.cast(tf.shape(k)[-1], tf.float32))\n","  if mask is not None:\n","    scaled_attention_logits += (mask * -1e9)\n","  # Normalize the last axis (sequence_len_k) using softmax to ensure that the scores add up to 1\n","  attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1) # output_shape = (..., sequence_len_q, sequence_len_k)\n","  output = tf.matmul(attention_weights, v) # output_shape = (..., sequence_len_q, depth_v)\n","  return output, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"jDY034UlTFy6"},"source":["# **Implementing The Multi-Head Attention Mechanism**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CT3B34NGNx9b"},"outputs":[],"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, *, d_dimensional_model, num_heads):\n","    super(MultiHeadAttention, self).__init__()\n","    self.num_heads = num_heads\n","    self.d_dimensional_model = d_dimensional_model\n","\n","    assert d_dimensional_model % self.num_heads == 0\n","    self.depth = d_dimensional_model//self.num_heads\n","    self.wq = tf.keras.layers.Dense(d_dimensional_model)\n","    self.wk = tf.keras.layers.Dense(d_dimensional_model)\n","    self.wv = tf.keras.layers.Dense(d_dimensional_model)\n","    self.dense = tf.keras.layers.Dense(d_dimensional_model)\n","\n","  def split_heads(self, x, batch_size):\n","    '''\n","    Split the last dimension into (num_heads, depth) and transpose the result such that the shape = (batch_size, num_heads, sequence_len, depth)\n","    '''\n","    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(x, perm = [0, 2, 1, 3])\n","\n","  def call(self, v, k, q , mask):\n","    batch_size = tf.shape(q)[0]\n","\n","    q = self.wq(q) # Shape: (batch_size, sequence_len, d_dimensional_model)\n","    q = self.split_heads(q, batch_size) # Shape: (batch_size, num_heads, sequence_len_q, depth)\n","    k = self.wk(k) # Shape: (batch_size, sequence_len, d_dimensional_model)\n","    k = self.split_heads(k, batch_size) # Shape: (batch_size, num_heads, sequence_len_k, depth)\n","    v = self.wv(v) # Shape: (batch_size, sequence_len, d_dimensional_model)\n","    v = self.split_heads(v, batch_size) # Shape: (batch_size, num_heads, sequence_len_v, depth)\n","\n","    '''\n","    scaled_attention.shape == (batch_size, num_heads, sequence_len_q, depth)\n","    attention_weights.shape == (batch_size, num_heads, sequence_len_q, sequence_len_k)\n","    '''\n","    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n","    scaled_attention = tf.transpose(scaled_attention, perm = [0, 2, 1, 3]) # Reshaped to (batch_size, sequence_len_q, num_heads, depth)\n","    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_dimensional_model)) # Shape: (batch_size, sequence_len_q, d_dimensional_model)\n","    output = self.dense(concat_attention) # Shape: (batch_size, sequence_len_q, d_dimensional_model)\n","    return output, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"jIove5cDTQYg"},"source":["# **Defining The Point-Wise Feed-Forward Network (2 Fully-Connected Layers)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"byaDrqePTgQL"},"outputs":[],"source":["def pointwise_feed_forward_network(d_dimensional_model, dff):\n","  return tf.keras.Sequential([tf.keras.layers.Dense(dff, activation = 'relu'), tf.keras.layers.Dense(d_dimensional_model)])"]},{"cell_type":"markdown","metadata":{"id":"F4ShrRBGUPW9"},"source":["# **Defining The Encoder And Decoder Layers**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"att84KsSUXwv"},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, *, d_dimensional_model, num_heads, dff, dropout_rate = 0.1):\n","    super(EncoderLayer, self).__init__()\n","    self.MHA = MultiHeadAttention(d_dimensional_model = d_dimensional_model, num_heads = num_heads)\n","    self.FFN = pointwise_feed_forward_network(d_dimensional_model, dff)\n","\n","    self.LayerNorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n","    self.LayerNorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n","\n","    self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n","    self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n","\n","  def call(self, x, training, mask):\n","    attention_output, _ = self.MHA(x, x, x, mask) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n","    attention_output = self.dropout1(attention_output, training = training)\n","    output1 = self.LayerNorm1(x + attention_output) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n","    FFN_output = self.FFN(output1) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n","    FFN_output = self.dropout2(FFN_output, training = training)\n","    output2 = self.LayerNorm2(output1 + FFN_output) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n","    return output2\n","\n","class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, *, d_dimensional_model, num_heads, dff, dropout_rate = 0.1):\n","    super(DecoderLayer, self).__init__()\n","    self.MHA1 = MultiHeadAttention(d_dimensional_model = d_dimensional_model, num_heads = num_heads)\n","    self.MHA2 = MultiHeadAttention(d_dimensional_model = d_dimensional_model, num_heads = num_heads)\n","\n","    self.FFN = pointwise_feed_forward_network(d_dimensional_model, dff)\n","\n","    self.LayerNorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n","    self.LayerNorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n","    self.LayerNorm3 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n","\n","    self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n","    self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n","    self.dropout3 = tf.keras.layers.Dropout(dropout_rate)\n","\n","  def call(self, x, encoder_output, training, lookahead_mask, padding_mask):\n","    '''\n","    encoder_output.shape: (batch_size, input_sequence_len, d_dimensional_model)\n","    '''\n","    attention1, attention_weights_block1 = self.MHA1(x, x, x, lookahead_mask) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n","    attention1 = self.dropout1(attention1, training = training)\n","    output1 = self.LayerNorm1(attention1 + x)\n","\n","    attention2, attention_weights_block2 = self.MHA2(encoder_output, encoder_output, output1, padding_mask) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n","    attention2 = self.dropout2(attention2, training = training)\n","    output2 = self.LayerNorm2(attention2 + output1) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n","\n","    FFN_output = self.FFN(output2) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n","    FFN_output = self.dropout3(FFN_output, training = training)\n","    output3 = self.LayerNorm3(FFN_output + output2) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n","    return output3, attention_weights_block1, attention_weights_block2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y95ZyKOnbRFT"},"outputs":[],"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, *, num_layers, d_dimensional_model, num_heads, dff, input_vocab_size, dropout_rate = 0.1):\n","    super(Encoder, self).__init__()\n","    self.d_dimensional_model = d_dimensional_model\n","    self.num_layers = num_layers\n","    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_dimensional_model)\n","    self.positional_encoding = positional_encoding(128, self.d_dimensional_model)\n","    self.encoder_layers = [EncoderLayer(d_dimensional_model = d_dimensional_model, num_heads = num_heads, dff = dff, dropout_rate = dropout_rate)\n","    for _ in range(num_layers)]\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","\n","  def call(self, x, training, mask):\n","    sequence_len = tf.shape(x)[1]\n","    # Adding embedding and positional encoding\n","    x = self.embedding(x) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n","    x *= tf.math.sqrt(tf.cast(self.d_dimensional_model, tf.float32))\n","    x += self.positional_encoding[:, :sequence_len, :]\n","    x = self.dropout(x, training = training)\n","    for j in range(self.num_layers):\n","      x = self.encoder_layers[j](x, training, mask)\n","    return x # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n","\n","class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, *, num_layers, d_dimensional_model, num_heads, dff, target_vocab_size, dropout_rate = 0.1):\n","    super(Decoder, self).__init__()\n","    self.d_dimensional_model = d_dimensional_model\n","    self.num_layers = num_layers\n","    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_dimensional_model)\n","    self.positional_encoding = positional_encoding(128, d_dimensional_model)\n","    self.decoder_layers = [DecoderLayer(d_dimensional_model = d_dimensional_model, num_heads = num_heads, dff = dff, dropout_rate = dropout_rate)\n","    for _ in range(num_layers)]\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","\n","  def call(self, x, encoder_output, training, lookahead_mask, padding_mask):\n","    sequence_len = tf.shape(x)[1]\n","    attention_weights = {}\n","    x = self.embedding(x) # Shape: (batch_size, target_sequence_len, d_dimensional_model)\n","    x *= tf.math.sqrt(tf.cast(self.d_dimensional_model, tf.float32))\n","    x += self.positional_encoding[:, :sequence_len, :]\n","    x = self.dropout(x, training = training)\n","\n","    for k in range(self.num_layers):\n","      x, block1, block2 = self.decoder_layers[k](x, encoder_output, training, lookahead_mask, padding_mask)\n","      attention_weights['decoder_layer{}_block1'.format(k+1)] = block1\n","      attention_weights['decoder_layer{}_block2'.format(k+1)] = block2\n","    return x, attention_weights # x.shape: (batch_size, target_sequence_len, d_dimensional_model)"]},{"cell_type":"markdown","metadata":{"id":"T6dm6WYIFmTq"},"source":["# **Defining The Transformer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eddzm6A1FhGH"},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","  def __init__(self, *, num_layers, d_dimensional_model, num_heads, dff, input_vocab_size, target_vocab_size, dropout_rate = 0.1):\n","    super().__init__()\n","    self.encoder = Encoder(num_layers = num_layers, d_dimensional_model = d_dimensional_model, num_heads = num_heads, dff = dff,\n","                           input_vocab_size = input_vocab_size, dropout_rate = dropout_rate)\n","    self.decoder = Decoder(num_layers = num_layers, d_dimensional_model = d_dimensional_model, num_heads = num_heads, dff = dff,\n","                           target_vocab_size = target_vocab_size, dropout_rate = dropout_rate)\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","  def call(self, inputs, training):\n","    input, target = inputs\n","    encoder_padding_mask, lookahead_mask, decoder_padding_mask = self.create_masks(input, target)\n","    encoder_output = self.encoder(input, training, encoder_padding_mask) # Shape: (batch_size, input_sequence_len, d_dimensional_model)\n","    # decoder_output.shape: (batch_size, target_sequence_len, d_dimensional_model)\n","    decoder_output, attention_weights = self.decoder(target, encoder_output, training, lookahead_mask, decoder_padding_mask)\n","    final_output = self.final_layer(decoder_output) # Shape: (batch_size, target_sequence_len, target_vocab_size)\n","    return final_output, attention_weights\n","\n","  def create_masks(self, input, target):\n","    encoder_padding_mask = create_padding_mask(input)\n","    # This padding mask is used in the second attention block of the decoder to mask out the encoder outputs\n","    decoder_padding_mask = create_padding_mask(input)\n","    # This lookahead mask is used in the first attention block of the decoder to pad and mask future tokens in the input received by the decoder\n","    lookahead_mask = create_lookahead_mask(tf.shape(target)[1])\n","    decoder_target_padding_mask = create_padding_mask(target)\n","    lookahead_mask = tf.maximum(decoder_target_padding_mask, lookahead_mask)\n","    return encoder_padding_mask, lookahead_mask, decoder_padding_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zAPeHy8VJWI3"},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_dimensional_model, warmup_steps = 4000):\n","    super(CustomSchedule, self).__init__()\n","    self.d_dimensional_model = d_dimensional_model\n","    self.d_dimensional_model = tf.cast(self.d_dimensional_model, tf.float32)\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    step = tf.cast(step, tf.float32)\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** (-1.5))\n","    return tf.math.rsqrt(self.d_dimensional_model) * tf.math.minimum(arg1, arg2)\n","\n","learning_rate = CustomSchedule(128)\n","translation_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OsfK2sOHLeXk"},"outputs":[],"source":["def loss_function(actual, prediction):\n","  mask = tf.math.logical_not(tf.math.equal(actual, 0))\n","  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n","  loss = loss_object(actual, prediction)\n","  mask = tf.cast(mask, dtype = loss.dtype)\n","  loss *= mask\n","  return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n","\n","def accuracy_function(actual, prediction):\n","  accuracies = tf.equal(actual, tf.argmax(prediction, axis = 2))\n","  mask = tf.math.logical_not(tf.math.equal(actual, 0))\n","  accuracies = tf.math.logical_and(mask, accuracies)\n","\n","  accuracies = tf.cast(accuracies, dtype = tf.float32)\n","  mask = tf.cast(mask, dtype = tf.float32)\n","  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n","\n","training_loss = tf.keras.metrics.Mean(name = 'train_loss')\n","training_accuracy = tf.keras.metrics.Mean(name = 'train_accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dzDRb3YFNqdq"},"outputs":[],"source":["translation_transformer = Transformer(num_layers = 4, d_dimensional_model = 128, num_heads = 8, dff = 512,\n","                                      input_vocab_size = translation_tokenizers.pt.get_vocab_size().numpy(),\n","                                      target_vocab_size = translation_tokenizers.en.get_vocab_size().numpy(), dropout_rate = 0.1)\n","\n","translation_checkpoint_path = 'Checkpoints/train'\n","translation_checkpoint = tf.train.Checkpoint(transformer = translation_transformer, optimizer = translation_optimizer)\n","translation_checkpoint_manager = tf.train.CheckpointManager(translation_checkpoint, translation_checkpoint_path, max_to_keep = 5)\n","\n","# If a checkpoint exists, restore the latest checkpoint\n","if translation_checkpoint_manager.latest_checkpoint:\n","  translation_checkpoint.restore(translation_checkpoint_manager.latest_checkpoint)\n","  print('Latest checkpoint restored!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1sm5j_hxR10n"},"outputs":[],"source":["train_step_signature = [tf.TensorSpec(shape = (None, None), dtype = tf.int64), tf.TensorSpec(shape = (None, None), dtype = tf.int64)]\n","\n","@tf.function(input_signature = train_step_signature)\n","def train_step(input, target):\n","  target_input = target[:, :-1]\n","  target_actual = target[:, 1:]\n","  with tf.GradientTape() as tape:\n","    predictions, _ = translation_transformer([input, target_input], training = True)\n","    loss = loss_function(target_actual, predictions)\n","  gradients = tape.gradient(loss, translation_transformer.trainable_variables)\n","  translation_optimizer.apply_gradients(zip(gradients, translation_transformer.trainable_variables))\n","  training_loss(loss)\n","  training_accuracy(accuracy_function(target_actual, predictions))"]},{"cell_type":"markdown","source":["# **Training The Transformer**"],"metadata":{"id":"pKuKZAggF6rL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4L1csXvTwX1","executionInfo":{"status":"ok","timestamp":1694582939884,"user_tz":-480,"elapsed":1706944,"user":{"displayName":"Edwin Goh Duo Yao","userId":"00967731948897399037"}},"outputId":"5699891b-8845-4fa5-8f5a-a9f16fdce890"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Batch 0: Loss = 8.8896, Accuracy = 0.0000\n","Epoch 1, Batch 50: Loss = 8.8225, Accuracy = 0.0012\n","Epoch 1, Batch 100: Loss = 8.7163, Accuracy = 0.0229\n","Epoch 1, Batch 150: Loss = 8.6014, Accuracy = 0.0353\n","Epoch 1, Batch 200: Loss = 8.4596, Accuracy = 0.0417\n","Epoch 1, Batch 250: Loss = 8.2898, Accuracy = 0.0466\n","Epoch 1, Batch 300: Loss = 8.0973, Accuracy = 0.0524\n","Epoch 1, Batch 350: Loss = 7.8965, Accuracy = 0.0607\n","Epoch 1, Batch 400: Loss = 7.7058, Accuracy = 0.0687\n","Epoch 1, Batch 450: Loss = 7.5375, Accuracy = 0.0754\n","Epoch 1, Batch 500: Loss = 7.3899, Accuracy = 0.0815\n","Epoch 1, Batch 550: Loss = 7.2555, Accuracy = 0.0883\n","Epoch 1, Batch 600: Loss = 7.1323, Accuracy = 0.0955\n","Epoch 1, Batch 650: Loss = 7.0171, Accuracy = 0.1024\n","Epoch 1, Batch 700: Loss = 6.9101, Accuracy = 0.1088\n","Epoch 2, Batch 0: Loss = 5.6769, Accuracy = 0.1845\n","Epoch 2, Batch 50: Loss = 5.4008, Accuracy = 0.1988\n","Epoch 2, Batch 100: Loss = 5.3558, Accuracy = 0.2005\n","Epoch 2, Batch 150: Loss = 5.3169, Accuracy = 0.2036\n","Epoch 2, Batch 200: Loss = 5.2841, Accuracy = 0.2067\n","Epoch 2, Batch 250: Loss = 5.2595, Accuracy = 0.2097\n","Epoch 2, Batch 300: Loss = 5.2366, Accuracy = 0.2119\n","Epoch 2, Batch 350: Loss = 5.2051, Accuracy = 0.2156\n","Epoch 2, Batch 400: Loss = 5.1853, Accuracy = 0.2178\n","Epoch 2, Batch 450: Loss = 5.1580, Accuracy = 0.2203\n","Epoch 2, Batch 500: Loss = 5.1341, Accuracy = 0.2228\n","Epoch 2, Batch 550: Loss = 5.1113, Accuracy = 0.2252\n","Epoch 2, Batch 600: Loss = 5.0885, Accuracy = 0.2273\n","Epoch 2, Batch 650: Loss = 5.0660, Accuracy = 0.2296\n","Epoch 3, Batch 0: Loss = 4.4578, Accuracy = 0.2832\n","Epoch 3, Batch 50: Loss = 4.7168, Accuracy = 0.2638\n","Epoch 3, Batch 100: Loss = 4.6948, Accuracy = 0.2650\n","Epoch 3, Batch 150: Loss = 4.6901, Accuracy = 0.2647\n","Epoch 3, Batch 200: Loss = 4.6690, Accuracy = 0.2664\n","Epoch 3, Batch 250: Loss = 4.6545, Accuracy = 0.2676\n","Epoch 3, Batch 300: Loss = 4.6427, Accuracy = 0.2686\n","Epoch 3, Batch 350: Loss = 4.6250, Accuracy = 0.2703\n","Epoch 3, Batch 400: Loss = 4.6127, Accuracy = 0.2716\n","Epoch 3, Batch 450: Loss = 4.6003, Accuracy = 0.2728\n","Epoch 3, Batch 500: Loss = 4.5827, Accuracy = 0.2746\n","Epoch 3, Batch 550: Loss = 4.5676, Accuracy = 0.2762\n","Epoch 3, Batch 600: Loss = 4.5563, Accuracy = 0.2775\n","Epoch 3, Batch 650: Loss = 4.5435, Accuracy = 0.2789\n","Epoch 4, Batch 0: Loss = 4.2364, Accuracy = 0.3115\n","Epoch 4, Batch 50: Loss = 4.2522, Accuracy = 0.3109\n","Epoch 4, Batch 100: Loss = 4.2079, Accuracy = 0.3162\n","Epoch 4, Batch 150: Loss = 4.1912, Accuracy = 0.3182\n","Epoch 4, Batch 200: Loss = 4.1778, Accuracy = 0.3190\n","Epoch 4, Batch 250: Loss = 4.1689, Accuracy = 0.3202\n","Epoch 4, Batch 300: Loss = 4.1514, Accuracy = 0.3228\n","Epoch 4, Batch 350: Loss = 4.1376, Accuracy = 0.3246\n","Epoch 4, Batch 400: Loss = 4.1209, Accuracy = 0.3268\n","Epoch 4, Batch 450: Loss = 4.1041, Accuracy = 0.3292\n","Epoch 4, Batch 500: Loss = 4.0857, Accuracy = 0.3314\n","Epoch 4, Batch 550: Loss = 4.0698, Accuracy = 0.3334\n","Epoch 4, Batch 600: Loss = 4.0574, Accuracy = 0.3351\n","Epoch 4, Batch 650: Loss = 4.0428, Accuracy = 0.3369\n","Epoch 4, Batch 700: Loss = 4.0271, Accuracy = 0.3390\n","Epoch 5, Batch 0: Loss = 3.8613, Accuracy = 0.3511\n","Epoch 5, Batch 50: Loss = 3.7514, Accuracy = 0.3694\n","Epoch 5, Batch 100: Loss = 3.7255, Accuracy = 0.3733\n","Epoch 5, Batch 150: Loss = 3.7052, Accuracy = 0.3764\n","Epoch 5, Batch 200: Loss = 3.6987, Accuracy = 0.3775\n","Epoch 5, Batch 250: Loss = 3.6819, Accuracy = 0.3798\n","Epoch 5, Batch 300: Loss = 3.6704, Accuracy = 0.3814\n","Epoch 5, Batch 350: Loss = 3.6588, Accuracy = 0.3829\n","Epoch 5, Batch 400: Loss = 3.6439, Accuracy = 0.3847\n","Epoch 5, Batch 450: Loss = 3.6333, Accuracy = 0.3859\n","Epoch 5, Batch 500: Loss = 3.6177, Accuracy = 0.3879\n","Epoch 5, Batch 550: Loss = 3.6027, Accuracy = 0.3900\n","Epoch 5, Batch 600: Loss = 3.5917, Accuracy = 0.3913\n","Epoch 5, Batch 650: Loss = 3.5833, Accuracy = 0.3927\n","Saving checkpoint for epoch 5 at Checkpoints/train/ckpt-1\n","Epoch 5: Loss = 3.5717, Accuracy = 0.3941\n","Time taken to complete 1 epoch: 80.15s\n","\n","Epoch 6, Batch 0: Loss = 3.4539, Accuracy = 0.3926\n","Epoch 6, Batch 50: Loss = 3.3351, Accuracy = 0.4195\n","Epoch 6, Batch 100: Loss = 3.3065, Accuracy = 0.4235\n","Epoch 6, Batch 150: Loss = 3.2953, Accuracy = 0.4253\n","Epoch 6, Batch 200: Loss = 3.2890, Accuracy = 0.4265\n","Epoch 6, Batch 250: Loss = 3.2785, Accuracy = 0.4282\n","Epoch 6, Batch 300: Loss = 3.2762, Accuracy = 0.4287\n","Epoch 6, Batch 350: Loss = 3.2669, Accuracy = 0.4299\n","Epoch 6, Batch 400: Loss = 3.2586, Accuracy = 0.4314\n","Epoch 6, Batch 450: Loss = 3.2516, Accuracy = 0.4325\n","Epoch 6, Batch 500: Loss = 3.2479, Accuracy = 0.4330\n","Epoch 6, Batch 550: Loss = 3.2429, Accuracy = 0.4338\n","Epoch 6, Batch 600: Loss = 3.2359, Accuracy = 0.4348\n","Epoch 6, Batch 650: Loss = 3.2266, Accuracy = 0.4361\n","Epoch 7, Batch 0: Loss = 2.8944, Accuracy = 0.4900\n","Epoch 7, Batch 50: Loss = 3.0027, Accuracy = 0.4612\n","Epoch 7, Batch 100: Loss = 2.9695, Accuracy = 0.4657\n","Epoch 7, Batch 150: Loss = 2.9628, Accuracy = 0.4669\n","Epoch 7, Batch 200: Loss = 2.9603, Accuracy = 0.4674\n","Epoch 7, Batch 250: Loss = 2.9497, Accuracy = 0.4692\n","Epoch 7, Batch 300: Loss = 2.9390, Accuracy = 0.4702\n","Epoch 7, Batch 350: Loss = 2.9316, Accuracy = 0.4711\n","Epoch 7, Batch 400: Loss = 2.9241, Accuracy = 0.4722\n","Epoch 7, Batch 450: Loss = 2.9205, Accuracy = 0.4727\n","Epoch 7, Batch 500: Loss = 2.9122, Accuracy = 0.4740\n","Epoch 7, Batch 550: Loss = 2.9048, Accuracy = 0.4754\n","Epoch 7, Batch 600: Loss = 2.8990, Accuracy = 0.4763\n","Epoch 7, Batch 650: Loss = 2.8957, Accuracy = 0.4769\n","Epoch 7, Batch 700: Loss = 2.8893, Accuracy = 0.4779\n","Epoch 8, Batch 0: Loss = 2.5528, Accuracy = 0.5245\n","Epoch 8, Batch 50: Loss = 2.6389, Accuracy = 0.5092\n","Epoch 8, Batch 100: Loss = 2.6416, Accuracy = 0.5092\n","Epoch 8, Batch 150: Loss = 2.6359, Accuracy = 0.5096\n","Epoch 8, Batch 200: Loss = 2.6440, Accuracy = 0.5085\n","Epoch 8, Batch 250: Loss = 2.6389, Accuracy = 0.5095\n","Epoch 8, Batch 300: Loss = 2.6373, Accuracy = 0.5097\n","Epoch 8, Batch 350: Loss = 2.6292, Accuracy = 0.5111\n","Epoch 8, Batch 400: Loss = 2.6247, Accuracy = 0.5119\n","Epoch 8, Batch 450: Loss = 2.6225, Accuracy = 0.5121\n","Epoch 8, Batch 500: Loss = 2.6188, Accuracy = 0.5127\n","Epoch 8, Batch 550: Loss = 2.6161, Accuracy = 0.5131\n","Epoch 8, Batch 600: Loss = 2.6131, Accuracy = 0.5136\n","Epoch 8, Batch 650: Loss = 2.6122, Accuracy = 0.5141\n","Epoch 8, Batch 700: Loss = 2.6091, Accuracy = 0.5146\n","Epoch 9, Batch 0: Loss = 2.3304, Accuracy = 0.5537\n","Epoch 9, Batch 50: Loss = 2.4259, Accuracy = 0.5373\n","Epoch 9, Batch 100: Loss = 2.4242, Accuracy = 0.5384\n","Epoch 9, Batch 150: Loss = 2.4232, Accuracy = 0.5388\n","Epoch 9, Batch 200: Loss = 2.4177, Accuracy = 0.5400\n","Epoch 9, Batch 250: Loss = 2.4221, Accuracy = 0.5395\n","Epoch 9, Batch 300: Loss = 2.4219, Accuracy = 0.5388\n","Epoch 9, Batch 350: Loss = 2.4215, Accuracy = 0.5388\n","Epoch 9, Batch 400: Loss = 2.4161, Accuracy = 0.5395\n","Epoch 9, Batch 450: Loss = 2.4113, Accuracy = 0.5405\n","Epoch 9, Batch 500: Loss = 2.4091, Accuracy = 0.5408\n","Epoch 9, Batch 550: Loss = 2.4105, Accuracy = 0.5405\n","Epoch 9, Batch 600: Loss = 2.4068, Accuracy = 0.5411\n","Epoch 9, Batch 650: Loss = 2.4062, Accuracy = 0.5415\n","Epoch 9, Batch 700: Loss = 2.4071, Accuracy = 0.5416\n","Epoch 10, Batch 0: Loss = 2.3411, Accuracy = 0.5385\n","Epoch 10, Batch 50: Loss = 2.2501, Accuracy = 0.5641\n","Epoch 10, Batch 100: Loss = 2.2483, Accuracy = 0.5628\n","Epoch 10, Batch 150: Loss = 2.2326, Accuracy = 0.5645\n","Epoch 10, Batch 200: Loss = 2.2429, Accuracy = 0.5631\n","Epoch 10, Batch 250: Loss = 2.2430, Accuracy = 0.5630\n","Epoch 10, Batch 300: Loss = 2.2454, Accuracy = 0.5628\n","Epoch 10, Batch 350: Loss = 2.2440, Accuracy = 0.5635\n","Epoch 10, Batch 400: Loss = 2.2429, Accuracy = 0.5635\n","Epoch 10, Batch 450: Loss = 2.2448, Accuracy = 0.5632\n","Epoch 10, Batch 500: Loss = 2.2437, Accuracy = 0.5636\n","Epoch 10, Batch 550: Loss = 2.2445, Accuracy = 0.5636\n","Epoch 10, Batch 600: Loss = 2.2445, Accuracy = 0.5638\n","Epoch 10, Batch 650: Loss = 2.2455, Accuracy = 0.5637\n","Saving checkpoint for epoch 10 at Checkpoints/train/ckpt-2\n","Epoch 10: Loss = 2.2464, Accuracy = 0.5637\n","Time taken to complete 1 epoch: 75.91s\n","\n","Epoch 11, Batch 0: Loss = 2.1877, Accuracy = 0.5663\n","Epoch 11, Batch 50: Loss = 2.1172, Accuracy = 0.5813\n","Epoch 11, Batch 100: Loss = 2.1160, Accuracy = 0.5803\n","Epoch 11, Batch 150: Loss = 2.1175, Accuracy = 0.5806\n","Epoch 11, Batch 200: Loss = 2.1083, Accuracy = 0.5823\n","Epoch 11, Batch 250: Loss = 2.1108, Accuracy = 0.5820\n","Epoch 11, Batch 300: Loss = 2.1137, Accuracy = 0.5818\n","Epoch 11, Batch 350: Loss = 2.1188, Accuracy = 0.5809\n","Epoch 11, Batch 400: Loss = 2.1189, Accuracy = 0.5808\n","Epoch 11, Batch 450: Loss = 2.1199, Accuracy = 0.5808\n","Epoch 11, Batch 500: Loss = 2.1194, Accuracy = 0.5810\n","Epoch 11, Batch 550: Loss = 2.1192, Accuracy = 0.5811\n","Epoch 11, Batch 600: Loss = 2.1193, Accuracy = 0.5813\n","Epoch 11, Batch 650: Loss = 2.1210, Accuracy = 0.5811\n","Epoch 11, Batch 700: Loss = 2.1199, Accuracy = 0.5816\n","Epoch 12, Batch 0: Loss = 2.0620, Accuracy = 0.5942\n","Epoch 12, Batch 50: Loss = 2.0041, Accuracy = 0.5964\n","Epoch 12, Batch 100: Loss = 1.9875, Accuracy = 0.5995\n","Epoch 12, Batch 150: Loss = 1.9872, Accuracy = 0.5998\n","Epoch 12, Batch 200: Loss = 1.9894, Accuracy = 0.5995\n","Epoch 12, Batch 250: Loss = 1.9941, Accuracy = 0.5990\n","Epoch 12, Batch 300: Loss = 1.9973, Accuracy = 0.5985\n","Epoch 12, Batch 350: Loss = 1.9990, Accuracy = 0.5980\n","Epoch 12, Batch 400: Loss = 2.0009, Accuracy = 0.5975\n","Epoch 12, Batch 450: Loss = 2.0002, Accuracy = 0.5978\n","Epoch 12, Batch 500: Loss = 2.0030, Accuracy = 0.5975\n","Epoch 12, Batch 550: Loss = 2.0032, Accuracy = 0.5975\n","Epoch 12, Batch 600: Loss = 2.0049, Accuracy = 0.5974\n","Epoch 12, Batch 650: Loss = 2.0058, Accuracy = 0.5973\n","Epoch 12, Batch 700: Loss = 2.0070, Accuracy = 0.5973\n","Epoch 13, Batch 0: Loss = 1.7758, Accuracy = 0.6195\n","Epoch 13, Batch 50: Loss = 1.8767, Accuracy = 0.6141\n","Epoch 13, Batch 100: Loss = 1.8901, Accuracy = 0.6136\n","Epoch 13, Batch 150: Loss = 1.8955, Accuracy = 0.6127\n","Epoch 13, Batch 200: Loss = 1.9005, Accuracy = 0.6112\n","Epoch 13, Batch 250: Loss = 1.9032, Accuracy = 0.6109\n","Epoch 13, Batch 300: Loss = 1.9040, Accuracy = 0.6109\n","Epoch 13, Batch 350: Loss = 1.9051, Accuracy = 0.6110\n","Epoch 13, Batch 400: Loss = 1.9104, Accuracy = 0.6104\n","Epoch 13, Batch 450: Loss = 1.9121, Accuracy = 0.6103\n","Epoch 13, Batch 500: Loss = 1.9124, Accuracy = 0.6103\n","Epoch 13, Batch 550: Loss = 1.9138, Accuracy = 0.6102\n","Epoch 13, Batch 600: Loss = 1.9144, Accuracy = 0.6104\n","Epoch 13, Batch 650: Loss = 1.9154, Accuracy = 0.6105\n","Epoch 13, Batch 700: Loss = 1.9171, Accuracy = 0.6104\n","Epoch 14, Batch 0: Loss = 1.6960, Accuracy = 0.6466\n","Epoch 14, Batch 50: Loss = 1.8020, Accuracy = 0.6274\n","Epoch 14, Batch 100: Loss = 1.8079, Accuracy = 0.6264\n","Epoch 14, Batch 150: Loss = 1.8072, Accuracy = 0.6267\n","Epoch 14, Batch 200: Loss = 1.8122, Accuracy = 0.6256\n","Epoch 14, Batch 250: Loss = 1.8111, Accuracy = 0.6257\n","Epoch 14, Batch 300: Loss = 1.8132, Accuracy = 0.6255\n","Epoch 14, Batch 350: Loss = 1.8171, Accuracy = 0.6250\n","Epoch 14, Batch 400: Loss = 1.8217, Accuracy = 0.6242\n","Epoch 14, Batch 450: Loss = 1.8229, Accuracy = 0.6242\n","Epoch 14, Batch 500: Loss = 1.8251, Accuracy = 0.6237\n","Epoch 14, Batch 550: Loss = 1.8275, Accuracy = 0.6233\n","Epoch 14, Batch 600: Loss = 1.8316, Accuracy = 0.6228\n","Epoch 14, Batch 650: Loss = 1.8360, Accuracy = 0.6222\n","Epoch 15, Batch 0: Loss = 1.9272, Accuracy = 0.6017\n","Epoch 15, Batch 50: Loss = 1.7216, Accuracy = 0.6416\n","Epoch 15, Batch 100: Loss = 1.7217, Accuracy = 0.6414\n","Epoch 15, Batch 150: Loss = 1.7256, Accuracy = 0.6400\n","Epoch 15, Batch 200: Loss = 1.7318, Accuracy = 0.6386\n","Epoch 15, Batch 250: Loss = 1.7385, Accuracy = 0.6371\n","Epoch 15, Batch 300: Loss = 1.7431, Accuracy = 0.6366\n","Epoch 15, Batch 350: Loss = 1.7504, Accuracy = 0.6355\n","Epoch 15, Batch 400: Loss = 1.7495, Accuracy = 0.6355\n","Epoch 15, Batch 450: Loss = 1.7546, Accuracy = 0.6344\n","Epoch 15, Batch 500: Loss = 1.7594, Accuracy = 0.6338\n","Epoch 15, Batch 550: Loss = 1.7613, Accuracy = 0.6335\n","Epoch 15, Batch 600: Loss = 1.7648, Accuracy = 0.6331\n","Epoch 15, Batch 650: Loss = 1.7687, Accuracy = 0.6326\n","Saving checkpoint for epoch 15 at Checkpoints/train/ckpt-3\n","Epoch 15: Loss = 1.7717, Accuracy = 0.6321\n","Time taken to complete 1 epoch: 76.26s\n","\n","Epoch 16, Batch 0: Loss = 1.8738, Accuracy = 0.6215\n","Epoch 16, Batch 50: Loss = 1.6611, Accuracy = 0.6474\n","Epoch 16, Batch 100: Loss = 1.6582, Accuracy = 0.6481\n","Epoch 16, Batch 150: Loss = 1.6703, Accuracy = 0.6459\n","Epoch 16, Batch 200: Loss = 1.6838, Accuracy = 0.6434\n","Epoch 16, Batch 250: Loss = 1.6826, Accuracy = 0.6440\n","Epoch 16, Batch 300: Loss = 1.6837, Accuracy = 0.6438\n","Epoch 16, Batch 350: Loss = 1.6872, Accuracy = 0.6435\n","Epoch 16, Batch 400: Loss = 1.6905, Accuracy = 0.6434\n","Epoch 16, Batch 450: Loss = 1.6949, Accuracy = 0.6426\n","Epoch 16, Batch 500: Loss = 1.7012, Accuracy = 0.6416\n","Epoch 16, Batch 550: Loss = 1.7059, Accuracy = 0.6410\n","Epoch 16, Batch 600: Loss = 1.7080, Accuracy = 0.6408\n","Epoch 16, Batch 650: Loss = 1.7104, Accuracy = 0.6404\n","Epoch 17, Batch 0: Loss = 1.6997, Accuracy = 0.6300\n","Epoch 17, Batch 50: Loss = 1.6064, Accuracy = 0.6563\n","Epoch 17, Batch 100: Loss = 1.6099, Accuracy = 0.6569\n","Epoch 17, Batch 150: Loss = 1.6192, Accuracy = 0.6546\n","Epoch 17, Batch 200: Loss = 1.6267, Accuracy = 0.6533\n","Epoch 17, Batch 250: Loss = 1.6303, Accuracy = 0.6528\n","Epoch 17, Batch 300: Loss = 1.6353, Accuracy = 0.6522\n","Epoch 17, Batch 350: Loss = 1.6406, Accuracy = 0.6511\n","Epoch 17, Batch 400: Loss = 1.6416, Accuracy = 0.6508\n","Epoch 17, Batch 450: Loss = 1.6454, Accuracy = 0.6504\n","Epoch 17, Batch 500: Loss = 1.6488, Accuracy = 0.6499\n","Epoch 17, Batch 550: Loss = 1.6510, Accuracy = 0.6498\n","Epoch 17, Batch 600: Loss = 1.6528, Accuracy = 0.6495\n","Epoch 17, Batch 650: Loss = 1.6549, Accuracy = 0.6495\n","Epoch 17, Batch 700: Loss = 1.6580, Accuracy = 0.6492\n","Epoch 18, Batch 0: Loss = 1.6114, Accuracy = 0.6550\n","Epoch 18, Batch 50: Loss = 1.5745, Accuracy = 0.6607\n","Epoch 18, Batch 100: Loss = 1.5720, Accuracy = 0.6608\n","Epoch 18, Batch 150: Loss = 1.5708, Accuracy = 0.6617\n","Epoch 18, Batch 200: Loss = 1.5762, Accuracy = 0.6610\n","Epoch 18, Batch 250: Loss = 1.5826, Accuracy = 0.6597\n","Epoch 18, Batch 300: Loss = 1.5857, Accuracy = 0.6596\n","Epoch 18, Batch 350: Loss = 1.5875, Accuracy = 0.6591\n","Epoch 18, Batch 400: Loss = 1.5924, Accuracy = 0.6587\n","Epoch 18, Batch 450: Loss = 1.5945, Accuracy = 0.6583\n","Epoch 18, Batch 500: Loss = 1.5961, Accuracy = 0.6580\n","Epoch 18, Batch 550: Loss = 1.5995, Accuracy = 0.6574\n","Epoch 18, Batch 600: Loss = 1.6007, Accuracy = 0.6571\n","Epoch 18, Batch 650: Loss = 1.6043, Accuracy = 0.6566\n","Epoch 18, Batch 700: Loss = 1.6070, Accuracy = 0.6564\n","Epoch 19, Batch 0: Loss = 1.5398, Accuracy = 0.6654\n","Epoch 19, Batch 50: Loss = 1.5057, Accuracy = 0.6718\n","Epoch 19, Batch 100: Loss = 1.5114, Accuracy = 0.6714\n","Epoch 19, Batch 150: Loss = 1.5132, Accuracy = 0.6709\n","Epoch 19, Batch 200: Loss = 1.5274, Accuracy = 0.6689\n","Epoch 19, Batch 250: Loss = 1.5274, Accuracy = 0.6688\n","Epoch 19, Batch 300: Loss = 1.5332, Accuracy = 0.6681\n","Epoch 19, Batch 350: Loss = 1.5383, Accuracy = 0.6673\n","Epoch 19, Batch 400: Loss = 1.5409, Accuracy = 0.6668\n","Epoch 19, Batch 450: Loss = 1.5420, Accuracy = 0.6667\n","Epoch 19, Batch 500: Loss = 1.5463, Accuracy = 0.6660\n","Epoch 19, Batch 550: Loss = 1.5509, Accuracy = 0.6654\n","Epoch 19, Batch 600: Loss = 1.5553, Accuracy = 0.6648\n","Epoch 19, Batch 650: Loss = 1.5583, Accuracy = 0.6644\n","Epoch 20, Batch 0: Loss = 1.4780, Accuracy = 0.6743\n","Epoch 20, Batch 50: Loss = 1.4760, Accuracy = 0.6743\n","Epoch 20, Batch 100: Loss = 1.4812, Accuracy = 0.6752\n","Epoch 20, Batch 150: Loss = 1.4831, Accuracy = 0.6745\n","Epoch 20, Batch 200: Loss = 1.4872, Accuracy = 0.6738\n","Epoch 20, Batch 250: Loss = 1.4906, Accuracy = 0.6736\n","Epoch 20, Batch 300: Loss = 1.4943, Accuracy = 0.6734\n","Epoch 20, Batch 350: Loss = 1.4996, Accuracy = 0.6723\n","Epoch 20, Batch 400: Loss = 1.5023, Accuracy = 0.6722\n","Epoch 20, Batch 450: Loss = 1.5032, Accuracy = 0.6720\n","Epoch 20, Batch 500: Loss = 1.5088, Accuracy = 0.6711\n","Epoch 20, Batch 550: Loss = 1.5131, Accuracy = 0.6704\n","Epoch 20, Batch 600: Loss = 1.5166, Accuracy = 0.6698\n","Epoch 20, Batch 650: Loss = 1.5196, Accuracy = 0.6694\n","Saving checkpoint for epoch 20 at Checkpoints/train/ckpt-4\n","Epoch 20: Loss = 1.5243, Accuracy = 0.6688\n","Time taken to complete 1 epoch: 75.13s\n","\n"]}],"source":["for epoch in range(20):\n","  start = time.perf_counter()\n","  training_loss.reset_states()\n","  training_accuracy.reset_states()\n","\n","  # Input: Portuguese; Target: English\n","  for batch, (input, target) in enumerate(translation_training_batches):\n","    train_step(input, target)\n","\n","    if batch % 50 == 0:\n","      print('Epoch {}, Batch {}: Loss = {:.4f}, Accuracy = {:.4f}'.format(epoch + 1, batch, training_loss.result(), training_accuracy.result()))\n","\n","  if (epoch + 1) % 5 == 0:\n","    checkpoint_save_path = translation_checkpoint_manager.save()\n","    print('Saving checkpoint for epoch {} at {}'.format(epoch + 1, checkpoint_save_path))\n","    print('Epoch {}: Loss = {:.4f}, Accuracy = {:.4f}'.format(epoch + 1, training_loss.result(), training_accuracy.result()))\n","    print('Time taken to complete 1 epoch: {:.2f}s\\n'.format(time.perf_counter() - start))"]},{"cell_type":"markdown","source":["# **Translation**"],"metadata":{"id":"PLkxsCrBAG8b"}},{"cell_type":"code","source":["class Translator(tf.Module):\n","  def __init__(self, tokenizers, transformer):\n","    self.tokenizers = tokenizers\n","    self.transformer = transformer\n","\n","  def __call__(self, sentence, max_length = 128):\n","    # Adding the start and end tokens since the input sentence is Portuguese\n","    assert isinstance(sentence, tf.Tensor)\n","    if len(sentence.shape) == 0:\n","      sentence = sentence[tf.newaxis]\n","    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n","    encoder_input = sentence\n","    # Initialize the output with the English start token since English is the output language\n","    start_end = self.tokenizers.en.tokenize([''])[0]\n","    start = start_end[0][tf.newaxis]\n","    end = start_end[1][tf.newaxis]\n","    # A 'tf.TensorArray' is required here, instead of a Python list' to ensure that dynamic-loop is traceable by 'tf.function'\n","    output_array = tf.TensorArray(dtype = tf.int64, size = 0, dynamic_size = True).write(0, start)\n","\n","    for a in tf.range(max_length):\n","      output = tf.transpose(output_array.stack())\n","      predictions, _ = self.transformer([encoder_input, output], training = False)\n","      # Select the last token from the sequence_len dimension\n","      predictions = predictions[:, -1:, :] # Shape: (batch_size, 1, vocab_size)\n","      prediction_id = tf.argmax(predictions, axis = -1)\n","      # Concatenate the prediction_id to the output which will be the decoder input\n","      output_array = output_array.write(a + 1, prediction_id[0])\n","      if prediction_id == end:\n","        break\n","    output = tf.transpose(output_array.stack()) # Shape: (1, tokens)\n","    text = self.tokenizers.en.detokenize(output)[0]\n","    tokens = self.tokenizers.en.lookup(output)[0]\n","    # 'tf.function' prevents the use of attention weights that were calculated during the last iteration, hence they need to be recalculated outside of the loop\n","    _, attention_weights = self.transformer([encoder_input, output[:, :-1]], training = False)\n","    return text, tokens, attention_weights"],"metadata":{"id":"ztzmDt_k9IwU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator = Translator(translation_tokenizers, translation_transformer)\n","\n","def translation_printer(sentence, tokens, ground_truth):\n","  print('Input: {:15s}'.format(sentence))\n","  print('Prediction: {:15s}'.format(tokens.numpy().decode('utf-8')))\n","  print('Ground truth: {:15s}'.format(ground_truth))\n","\n","input_sentence = 'os meus vizinhos ouviram sobre esta ideia.'\n","ground_truth = 'and my neighbouring homes heard about this idea.'\n","translated_text, translated_tokens, attention_weights = translator(tf.constant(input_sentence))\n","translation_printer(input_sentence, translated_text, ground_truth)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5g6lUmJGyRk","executionInfo":{"status":"ok","timestamp":1694584955680,"user_tz":-480,"elapsed":3585,"user":{"displayName":"Edwin Goh Duo Yao","userId":"00967731948897399037"}},"outputId":"6c27f794-173c-4f1e-da0a-1ff98ef6f2cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: os meus vizinhos ouviram sobre esta ideia.\n","Prediction: my neighbors have heard about this idea .\n","Ground truth: and my neighbouring homes heard about this idea.\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1b3a0kuHH2Ptdv3sLl7gQAqn0r79yrUEF","authorship_tag":"ABX9TyPNKm6dawmZlRItbwxjoErb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}