{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Pipeline - Automated ML\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/manymodels/03_Forecasting/03_Forecasting_Pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we create a pipeline for doing batch forecasting of 11,973 AutoML models. The training and scoring of these models was completed in the Training notebook in this repository. We will set up the Pipeline for forecasting given the desired forecasting horizon. We utitlize the AutoMLPipelineBuilder to parallelize the process. For more information about the Data and Models refer to the Data Preparation and Training Notebooks. \n",
    "\n",
    "The pipeline set up is similar to the Training Pipeline in this repository. For more details on the steps and functions refer to the Training folder. \n",
    "\n",
    "### Prerequisites \n",
    "At this point, you should have already:\n",
    "\n",
    "1. Created your AML Workspace using the [00_Setup_AML_Workspace notebook](../../00_Setup_AML_Workspace.ipynb)\n",
    "2. Run [01_Data_Preparation.ipynb](../../01_Data_Preparation.ipynb) to create the dataset\n",
    "3. Run [02_AutoML_Training_Pipeline.ipynb](../02_AutoML_Training_Pipeline/02_AutoML_Training_Pipeline.ipynb) to train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the azureml.contrib.automl.pipeline.steps package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml-contrib-automl-pipeline-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Call the Workspace, Datastore, and Compute\n",
    "\n",
    "As we did in the Training Pipeline notebook, we need to call the Workspace. We also want to create variables for the datastore and compute cluster. \n",
    "\n",
    "### Connect to the workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5406/1275382199.py:21: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>0c19fc19-85fd-4aa4-b133-61dd20fa93df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>auotml-example-workspace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>edwin.spartan117-rg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>southeastasia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Default datastore name</th>\n",
       "      <td>workspaceblobstore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            \n",
       "SDK version             1.51.0                              \n",
       "Subscription ID         0c19fc19-85fd-4aa4-b133-61dd20fa93df\n",
       "Workspace               auotml-example-workspace            \n",
       "Resource Group          edwin.spartan117-rg                 \n",
       "Location                southeastasia                       \n",
       "Default datastore name  workspaceblobstore                  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore\n",
    "import pandas as pd\n",
    "\n",
    "# set up workspace\n",
    "ws= Workspace.from_config(path = '../../config.json') \n",
    "\n",
    "# Take a look at Workspace\n",
    "ws.get_details()\n",
    "\n",
    "# set up datastores\n",
    "dstore = ws.get_default_datastore()\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Default datastore name'] = dstore.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach existing compute resource\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "Checking cluster status...\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = \"automl-cluster\"\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "cts = ws.compute_targets\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
    "    found = True\n",
    "    print('Found existing compute target.')\n",
    "    compute = cts[amlcompute_cluster_name]\n",
    "    \n",
    "if not found:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D16S_V3',\n",
    "                                                           min_nodes=2,\n",
    "                                                           max_nodes=20)\n",
    "    # Create the cluster.\n",
    "    compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "    \n",
    "print('Checking cluster status...')\n",
    "# Can poll for a minimum number of nodes and for a specific timeout.\n",
    "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "compute.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
    "    \n",
    "# For a more detailed view of current AmlCompute status, use get_status()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, 'MMSA-Forecasting-Pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Call Registered FileDataset\n",
    "In the Data Preparation notebook, we registered the orange juice inference data to the Workspace. You can choose to run the pipeline on the subet of 10 series or the full dataset of 11,973 series. We recommend starting with 10 series then expanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "filedst_10_models = Dataset.get_by_name(ws, name = 'Orange Juice Sales (Simulated) Subset - Inference')\n",
    "filedst_10_models_input = filedst_10_models.as_named_input('forecast_10_models')\n",
    " \n",
    "#filedst_all_models = Dataset.get_by_name(ws, name='oj_data_inference')\n",
    "#filedst_all_models_input = filedst_all_models.as_named_input('forecast_all_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Build forecasting pipeline\n",
    "Now that the data, models, and compute resources are set up, we can put together a pipeline for forecasting. \n",
    "### Set up the environment to run the script\n",
    "Specify the conda dependencies for your script. This will allow us to install packages and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_experiment_name = 'MMSA-Training-Pipeline'\n",
    "training_pipeline_run_id = \"d6c5edbc-f851-4882-a936-5df59b9ddaa7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the configuration to wrap the entry script \n",
    "AutoMLPipelineBuilder is used to build the inference step for many models. You will need to determine the number of workers and nodes appropriate for your use case. The process_count_per_node is based off the number of cores of the compute VM. The node_count will determine the number of master nodes to use, increasing the node count will speed up the training process.\n",
    "\n",
    "* <b>experiment</b>: Current experiment.\n",
    "\n",
    "* <b>inference_data</b>: Inference dataset.\n",
    "\n",
    "* <b>compute_target</b>: Compute target for inference.\n",
    "\n",
    "* <b>node_count</b>: The number of compute nodes to be used for running the user script. We recommend to start with 3 and increase the node_count if the training time is taking too long.\n",
    "\n",
    "* <b>process_count_per_node</b>: The number of processes per node.\n",
    "\n",
    "* <b>run_invocation_timeout</b>: The run() method invocation timeout in seconds. The timeout should be set to maximum training time of one AutoML run(with some buffer), by default it's 60 seconds.\n",
    "\n",
    "* <b>output_datastore</b>: Output datastore to output the inference results.\n",
    "\n",
    "* <b>train_experiment_name</b>: Training experiment name where many models were trained.\n",
    "\n",
    "* <b>train_run_id</b>: Training run id where many models were trained.\n",
    "\n",
    "* <b>partition_column_names</b>: Partition column names.\n",
    "\n",
    "* <b>time_column_name(Optional)</b>: Time column name if it is timeseries\n",
    "\n",
    "* <b>target_column_name(Optional)</b>: Target column name if the inference dataset has the target column\n",
    "\n",
    "<span style=\"color:red\"><b>NOTE: There are limits on how many runs we can do in parallel per workspace, and we currently recommend to set the parallelism to maximum of 320 runs per experiment per workspace. If users want to have more parallelism and increase this limit they might encounter Too Many Requests errors (HTTP 429). </b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter target_column_names will be deprecated in the future. Please use ManyModelsParameters instead.\n",
      "Parameter time_column_name will be deprecated in the future. Please use ManyModelsParameters instead.\n",
      "Parameter partition_column_names will be deprecated in the future. Please use ManyModelsParameters instead.\n",
      "Output in the txt file does not include column header, use 'csv' file extension in 'append_row_file_name' parameter in 'get_many_models_batch_inference_steps' method to get column header in the output file.\n"
     ]
    }
   ],
   "source": [
    "from azureml.contrib.automl.pipeline.steps import AutoMLPipelineBuilder\n",
    "\n",
    "partition_column_names = ['Store', 'Brand']\n",
    "\n",
    "inference_steps = AutoMLPipelineBuilder.get_many_models_batch_inference_steps(experiment = experiment,\n",
    "                                                                              inference_data = filedst_10_models_input,\n",
    "                                                                              compute_target = compute,\n",
    "                                                                              node_count = 1,\n",
    "                                                                              process_count_per_node = 4,\n",
    "                                                                              run_invocation_timeout=300,\n",
    "                                                                              output_datastore = dstore,\n",
    "                                                                              train_experiment_name = training_experiment_name,\n",
    "                                                                              train_run_id = training_pipeline_run_id,\n",
    "                                                                              partition_column_names = partition_column_names,\n",
    "                                                                              time_column_name = \"WeekStarting\",\n",
    "                                                                              target_column_name = \"Quantity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Run the forecast pipeline\n",
    "We can use the Experiment we created to track the runs of the pipeline and review the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step many-models-inference [7e006a13][569c3a3c-cb77-445e-bf6f-86a43250ac11], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 43771824-6025-4783-8086-a4b096f8bd2d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/43771824-6025-4783-8086-a4b096f8bd2d?wsid=/subscriptions/0c19fc19-85fd-4aa4-b133-61dd20fa93df/resourcegroups/edwin.spartan117-rg/workspaces/auotml-example-workspace&tid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace = ws, steps = inference_steps)\n",
    "run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the folowing command if you'd like to monitor the forecasting process in jupyter notebook. It will stream logs live while forecasting. \n",
    "\n",
    "**Note**: this command may not work for Notebook VM, however it should work on your local laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 43771824-6025-4783-8086-a4b096f8bd2d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/43771824-6025-4783-8086-a4b096f8bd2d?wsid=/subscriptions/0c19fc19-85fd-4aa4-b133-61dd20fa93df/resourcegroups/edwin.spartan117-rg/workspaces/auotml-example-workspace&tid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 595e6f95-c95d-475e-9363-d2673b88139d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/595e6f95-c95d-475e-9363-d2673b88139d?wsid=/subscriptions/0c19fc19-85fd-4aa4-b133-61dd20fa93df/resourcegroups/edwin.spartan117-rg/workspaces/auotml-example-workspace&tid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6\n",
      "StepRun( many-models-inference ) Status: NotStarted\n",
      "StepRun( many-models-inference ) Status: Running\n",
      "\n",
      "StepRun(many-models-inference) Execution Summary\n",
      "=================================================\n",
      "StepRun( many-models-inference ) Status: Finished\n",
      "{'runId': '595e6f95-c95d-475e-9363-d2673b88139d', 'target': 'automl-cluster', 'status': 'Completed', 'startTimeUtc': '2023-11-17T18:05:11.860745Z', 'endTimeUtc': '2023-11-17T18:07:13.719864Z', 'services': {}, 'properties': {'ContentSnapshotId': 'af1e4e09-0b9d-422b-b8b5-b1625840f72f', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '569c3a3c-cb77-445e-bf6f-86a43250ac11', 'azureml.moduleName': 'many-models-inference', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '7e006a13', 'azureml.pipelinerunid': '43771824-6025-4783-8086-a4b096f8bd2d', 'azureml.pipeline': '43771824-6025-4783-8086-a4b096f8bd2d', 'azureml.rootpipelinerunid': '43771824-6025-4783-8086-a4b096f8bd2d', 'azureml.pipelineComponent': 'masterescloud', 'azureml.parallelrunstep': 'true', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '14093d1b-5226-4747-8dc6-ca94abb97a68'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'forecast_10_models', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.51.0', '--scoring_module_name', 'many_models_inference_driver.py', '--mini_batch_size', '1', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '300', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZUREML_DATAREFERENCE_many_models_inference_output', '--process_count_per_node', '4', '--partition_column_names', 'Store', 'Brand', '--forecast_mode', 'recursive', '--step', '1', '--time_column_name', 'WeekStarting', '--target_column_name', 'Quantity', '--input_fds_0', 'forecast_10_models'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'ParallelTask', 'target': 'automl-cluster', 'dataReferences': {'many_models_inference_output': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/595e6f95-c95d-475e-9363-d2673b88139d/many_models_inference_output', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'forecast_10_models': {'dataLocation': {'dataset': {'id': '14093d1b-5226-4747-8dc6-ca94abb97a68', 'name': None, 'version': '3'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'environmentVariableName': 'forecast_10_models', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'AzureML-AutoML', 'version': '142', 'assetId': 'azureml://registries/azureml/environments/AzureML-AutoML/versions/142', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': True, 'condaDependencies': None, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': None, 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': 'FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\\n\\nENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml-automl\\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH/bin:$PATH\\n\\nCOPY --from=mcr.microsoft.com/azureml/mlflow-ubuntu20.04-py38-cpu-inference:20230306.v3 /var/mlflow_resources/mlflow_score_script.py /var/mlflow_resources/mlflow_score_script.py\\n\\nENV MLFLOW_MODEL_FOLDER=\"mlflow-model\"\\n# ENV AML_APP_ROOT=\"/var/mlflow_resources\"\\n# ENV AZUREML_ENTRY_SCRIPT=\"mlflow_score_script.py\"\\n\\nENV ENABLE_METADATA=true\\n\\n# begin conda create\\n# Create conda environment\\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\\\\n    python=3.8 \\\\\\n    # begin conda dependencies\\n    pip=22.1.2 \\\\\\n    numpy~=1.22.3 \\\\\\n    py-cpuinfo=5.0.0 \\\\\\n    joblib=1.2.0 \\\\\\n    cloudpickle=1.6.0 \\\\\\n    scikit-learn=0.22.1 \\\\\\n    pandas~=1.1.5 \\\\\\n    py-xgboost=1.3.3 \\\\\\n    holidays=0.10.3 \\\\\\n    setuptools-git \\\\\\n    setuptools=65.5.1 \\\\\\n    wheel=0.38.1 \\\\\\n    pyopenssl=23.2.0 \\\\\\n    \\'psutil>5.0.0,<6.0.0\\' \\\\\\n    # end conda dependencies\\n    -c conda-forge -c pytorch -c anaconda && \\\\\\n    conda run -p $AZUREML_CONDA_ENVIRONMENT_PATH && \\\\\\n    conda clean -a -y\\n# end conda create\\n\\n# begin pip install\\n# Install pip dependencies\\nRUN pip install  \\\\\\n                # begin pypi dependencies\\n                \\'cryptography==41.0.0\\' \\\\\\n                \\'azureml-core==1.52.0\\' \\\\\\n                \\'azureml-mlflow==1.52.0\\' \\\\\\n                \\'azureml-pipeline-core==1.52.0\\' \\\\\\n                \\'azureml-telemetry==1.52.0\\' \\\\\\n                \\'azureml-interpret==1.52.0\\' \\\\\\n                \\'azureml-responsibleai==1.52.0\\' \\\\\\n                \\'azureml-automl-core==1.52.0.post1\\' \\\\\\n                \\'azureml-automl-runtime==1.52.0.post1\\' \\\\\\n                \\'azureml-train-automl-client==1.52.0\\' \\\\\\n                \\'azureml-train-automl-runtime==1.52.0\\' \\\\\\n                \\'azureml-dataset-runtime==1.52.0\\' \\\\\\n                \\'azureml-defaults==1.52.0\\' \\\\\\n                \\'inference-schema\\' \\\\\\n                \\'fbprophet==0.7.1\\' \\\\\\n                \\'pystan==2.19.1.1\\' \\\\\\n                \\'notebook==6.4.9\\' \\\\\\n                \\'mltable>=1.0.0\\'\\n                # end pypi dependencies\\n# end pip install', 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': [41, 42], 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'DISABLE_ENV_MISMATCH': 'True', 'AUTOML_IGNORE_PACKAGE_VERSION_INCOMPATIBILITIES': 'True', 'AZUREML_FLUSH_INGEST_WAIT': '', 'AZUREML_OTEL_EXPORT_RH': '', 'AZUREML_METRICS_POLLING_INTERVAL': '30'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=7T3a8koXFYJLFL3%2FvgL8t0JwsNF8hmuN69qOPo3IbPc%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A59Z&ske=2023-11-18T23%3A39%3A59Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A53%3A11Z&se=2023-11-18T02%3A03%3A11Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=nOZH9zr09cWaVtM%2BzOTfL5t5Pd7zm3nyDOBW0E%2Fydt4%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A59Z&ske=2023-11-18T23%3A39%3A59Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A53%3A11Z&se=2023-11-18T02%3A03%3A11Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=LyTRB6Yzs1DcFPh4Y2wsRspkftCB%2BOAeACMCko8ueMU%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A59Z&ske=2023-11-18T23%3A39%3A59Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A53%3A11Z&se=2023-11-18T02%3A03%3A11Z&sp=r', 'user_logs/std_log_0.txt': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/user_logs/std_log_0.txt?sv=2019-07-07&sr=b&sig=GUoLz8FVou%2FqzFedd0DQm0U0big0ZYrQm7e0%2F7Qar3s%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A51Z&ske=2023-11-18T23%3A39%3A51Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A57%3A15Z&se=2023-11-18T02%3A07%3A15Z&sp=r', 'system_logs/cs_capability/0/cs-capability.log': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/system_logs/cs_capability/0/cs-capability.log?sv=2019-07-07&sr=b&sig=Xzj8F8kX3jp1BZI4eHNxXx7iyASZTY62sAZyNI7TqDY%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A53Z&ske=2023-11-18T23%3A39%3A53Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A57%3A15Z&se=2023-11-18T02%3A07%3A15Z&sp=r', 'system_logs/data_capability/0/data-capability.log': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/system_logs/data_capability/0/data-capability.log?sv=2019-07-07&sr=b&sig=JSkf2ZTj8H6Hpwz8IFRL8X3ZdzHXCQFtg76usrFt5Do%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A53Z&ske=2023-11-18T23%3A39%3A53Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A57%3A15Z&se=2023-11-18T02%3A07%3A15Z&sp=r', 'system_logs/data_capability/0/rslex.log.2023-11-17-18': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/system_logs/data_capability/0/rslex.log.2023-11-17-18?sv=2019-07-07&sr=b&sig=whyTg%2F6c8W7GvnBGF1ttmlHFPpZEdCx2F6u4vkFmRQk%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A53Z&ske=2023-11-18T23%3A39%3A53Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A57%3A15Z&se=2023-11-18T02%3A07%3A15Z&sp=r', 'system_logs/hosttools_capability/0/hosttools-capability.log': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/system_logs/hosttools_capability/0/hosttools-capability.log?sv=2019-07-07&sr=b&sig=yYdFGwp4x4I73XC49BGegdOsMe6qggIGbnW2silpmkE%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A53Z&ske=2023-11-18T23%3A39%3A53Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A57%3A15Z&se=2023-11-18T02%3A07%3A15Z&sp=r', 'system_logs/lifecycler/0/execution-wrapper.log': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/system_logs/lifecycler/0/execution-wrapper.log?sv=2019-07-07&sr=b&sig=79qVP5otwFuI0bPifhguODdsdjW0UY8OeOARvtlQ%2FH8%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A53Z&ske=2023-11-18T23%3A39%3A53Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A57%3A15Z&se=2023-11-18T02%3A07%3A15Z&sp=r', 'system_logs/lifecycler/0/lifecycler.log': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/system_logs/lifecycler/0/lifecycler.log?sv=2019-07-07&sr=b&sig=xTXvuQpzbJtpr0XrGLS%2FnD%2FaMDpq9VFl3g%2FMtkuUm1E%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A53Z&ske=2023-11-18T23%3A39%3A53Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A57%3A15Z&se=2023-11-18T02%3A07%3A15Z&sp=r', 'system_logs/metrics_capability/0/metrics-capability.log': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/system_logs/metrics_capability/0/metrics-capability.log?sv=2019-07-07&sr=b&sig=HprDpcRt3ys6zr0uWWaUKjuz0rSlZczdARp6O6uWhh8%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A53Z&ske=2023-11-18T23%3A39%3A53Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A57%3A15Z&se=2023-11-18T02%3A07%3A15Z&sp=r', 'system_logs/snapshot_capability/0/snapshot-capability.log': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.595e6f95-c95d-475e-9363-d2673b88139d/system_logs/snapshot_capability/0/snapshot-capability.log?sv=2019-07-07&sr=b&sig=iwjkJUdCoL6Jk7pSabVWHufT%2BbSkOeuwHBv5vgPjayk%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A29%3A53Z&ske=2023-11-18T23%3A39%3A53Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A57%3A15Z&se=2023-11-18T02%3A07%3A15Z&sp=r'}, 'submittedBy': 'Edwin Josiah Goh Duo Yao'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '43771824-6025-4783-8086-a4b096f8bd2d', 'status': 'Completed', 'startTimeUtc': '2023-11-17T18:03:04.65228Z', 'endTimeUtc': '2023-11-17T18:07:14.836746Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-11-17T18:03:05.1118187+00:00\",\"EndTime\":\"2023-11-17T18:07:14.7180816+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.43771824-6025-4783-8086-a4b096f8bd2d/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=Ggabce2uDfd8jC7tMkTjw9DYSLzo3eJ31Ivx%2FjxE2lE%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A36%3A19Z&ske=2023-11-18T23%3A46%3A19Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A53%3A32Z&se=2023-11-18T02%3A03%3A32Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.43771824-6025-4783-8086-a4b096f8bd2d/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=ap39vS9VEVeOuO88q%2Bpg%2FhS7HeHJlY5RyLc7jZfa%2Fw4%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A36%3A19Z&ske=2023-11-18T23%3A46%3A19Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A53%3A32Z&se=2023-11-18T02%3A03%3A32Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://auotmlexamplew5880114168.blob.core.windows.net/azureml/ExperimentRun/dcid.43771824-6025-4783-8086-a4b096f8bd2d/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=Ue%2BZh53rCw8gteP0MccAju9Rq3d4gTmCjf1E8c%2Fq988%3D&skoid=56ae5788-f7db-4b10-a19f-2849158c60aa&sktid=c5f4b1c2-b533-4788-b1c5-99d0f10fb9b6&skt=2023-11-17T15%3A36%3A19Z&ske=2023-11-18T23%3A46%3A19Z&sks=b&skv=2019-07-07&st=2023-11-17T17%3A53%3A32Z&se=2023-11-18T02%3A03%3A32Z&sp=r'}, 'submittedBy': 'Edwin Josiah Goh Duo Yao'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succesfully forecasted on AutoML Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Pipeline Outputs\n",
    "The forecasting pipeline forecasts the orange juice quantity for a Store by Brand. The pipeline returns one file with the predictions for each store and outputs the result to the forecasting_output Blob container. The details of the blob container is listed in 'forecasting_output.txt' under Outputs+logs. \n",
    "\n",
    "The following code snippet:\n",
    "1. Downloads the contents of the output folder that is passed in the parallel run step \n",
    "2. Reads the parallel_run_step.txt file that has the predictions as pandas dataframe and \n",
    "3. Displays the top 10 rows of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction has  190  rows. Here the first 10 rows are being displayed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week Starting</th>\n",
       "      <th>Store</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Advert</th>\n",
       "      <th>Price</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-05-28</td>\n",
       "      <td>1000</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>9130</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>21912.00</td>\n",
       "      <td>9084.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-06-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>11225</td>\n",
       "      <td>1</td>\n",
       "      <td>2.47</td>\n",
       "      <td>27725.75</td>\n",
       "      <td>11164.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-06-11</td>\n",
       "      <td>1000</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>14025</td>\n",
       "      <td>1</td>\n",
       "      <td>2.53</td>\n",
       "      <td>35483.25</td>\n",
       "      <td>14212.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-06-18</td>\n",
       "      <td>1000</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>16433</td>\n",
       "      <td>1</td>\n",
       "      <td>2.44</td>\n",
       "      <td>40096.52</td>\n",
       "      <td>16621.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-06-25</td>\n",
       "      <td>1000</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>16962</td>\n",
       "      <td>1</td>\n",
       "      <td>1.93</td>\n",
       "      <td>32736.66</td>\n",
       "      <td>16616.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1992-07-02</td>\n",
       "      <td>1000</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>10222</td>\n",
       "      <td>1</td>\n",
       "      <td>2.64</td>\n",
       "      <td>26986.08</td>\n",
       "      <td>9663.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1992-07-09</td>\n",
       "      <td>1000</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>18117</td>\n",
       "      <td>1</td>\n",
       "      <td>2.06</td>\n",
       "      <td>37321.02</td>\n",
       "      <td>17738.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1992-07-16</td>\n",
       "      <td>1000</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>11754</td>\n",
       "      <td>1</td>\n",
       "      <td>2.53</td>\n",
       "      <td>29737.62</td>\n",
       "      <td>11516.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1992-07-23</td>\n",
       "      <td>1000</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>13080</td>\n",
       "      <td>1</td>\n",
       "      <td>2.02</td>\n",
       "      <td>26421.60</td>\n",
       "      <td>13146.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1992-07-30</td>\n",
       "      <td>1000</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>19628</td>\n",
       "      <td>1</td>\n",
       "      <td>2.17</td>\n",
       "      <td>42592.76</td>\n",
       "      <td>19250.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Week Starting  Store      Brand  Quantity  Advert  Price  Revenue  Predicted\n",
       "0  1992-05-28    1000   dominicks  9130      1      2.40   21912.00 9084.28   \n",
       "1  1992-06-04    1000   dominicks  11225     1      2.47   27725.75 11164.66  \n",
       "2  1992-06-11    1000   dominicks  14025     1      2.53   35483.25 14212.47  \n",
       "3  1992-06-18    1000   dominicks  16433     1      2.44   40096.52 16621.67  \n",
       "4  1992-06-25    1000   dominicks  16962     1      1.93   32736.66 16616.88  \n",
       "5  1992-07-02    1000   dominicks  10222     1      2.64   26986.08 9663.17   \n",
       "6  1992-07-09    1000   dominicks  18117     1      2.06   37321.02 17738.26  \n",
       "7  1992-07-16    1000   dominicks  11754     1      2.53   29737.62 11516.38  \n",
       "8  1992-07-23    1000   dominicks  13080     1      2.02   26421.60 13146.02  \n",
       "9  1992-07-30    1000   dominicks  19628     1      2.17   42592.76 19250.35  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import sys \n",
    "from scripts.helper import get_forecasting_output\n",
    "\n",
    "forecasting_results_name = \"forecasting_results\"\n",
    "forecasting_output_name = \"many_models_inference_output\"\n",
    "\n",
    "forecast_file = get_forecasting_output(run, forecasting_results_name, forecasting_output_name)\n",
    "df = pd.read_csv(forecast_file, delimiter = \" \", header = None)\n",
    "df.columns = [\"Week Starting\", \"Store\", \"Brand\", \"Quantity\",  \"Advert\", \"Price\" , \"Revenue\", \"Predicted\" ]\n",
    "print(\"Prediction has \", df.shape[0], \" rows. Here the first 10 rows are being displayed.\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Publish and schedule the pipeline (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Publish the pipeline\n",
    "\n",
    "Once you have a pipeline you're happy with, you can publish a pipeline so you can call it programmatically later on. See this [tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-your-first-pipeline#publish-a-pipeline) for additional information on publishing and calling pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline.publish(name = 'automl_forecast_many_models', description = 'forecast many models',\n",
    "                                      version = '1', continue_on_step_failure = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Schedule the pipeline\n",
    "You can also [schedule the pipeline](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-schedule-pipelines) to run on a time-based or change-based schedule. This could be used to automatically retrain or forecast models every month or based on another trigger such as data drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "    \n",
    "# forecasting_pipeline_id = published_pipeline.id\n",
    "\n",
    "# recurrence = ScheduleRecurrence(frequency=\"Month\", interval=1, start_time=\"2020-01-01T09:00:00\")\n",
    "# recurring_schedule = Schedule.create(ws, name=\"automl_forecasting_recurring_schedule\", \n",
    "#                             description=\"Schedule Forecasting Pipeline to run on the first day of every week\",\n",
    "#                             pipeline_id=forecasting_pipeline_id, \n",
    "#                             experiment_name=experiment.name, \n",
    "#                             recurrence=recurrence)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "deeptim"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
